{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb5dc22e-2851-41d4-83ea-4fb16434cfbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.signal as signal\n",
    "from scipy.signal import convolve, find_peaks\n",
    "from scipy.signal import butter, sosfreqz, sosfiltfilt, filtfilt\n",
    "import scipy.io\n",
    "import h5py\n",
    "import os, sys\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import Normalize\n",
    "from matplotlib.widgets import Slider, Button, Cursor, CheckButtons\n",
    "from matplotlib.cm import ScalarMappable\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interactive, Output, IntSlider, FloatRangeSlider, IntRangeSlider, FloatSlider, interact, fixed, interactive_output, VBox, HBox, Dropdown, SelectMultiple, Button, widgets, Label\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog, OptionMenu, StringVar\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40da8849-0b0b-437c-abd9-d64653e807d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the full path to the EEG file (.bin, .npy, or .mat):  '/Volumes/kovi ssd/egyetem/7.felev-szakdoga/THUMB/patients/epi52_sleep/epi52_01_sleep_2_thumb_1.mat'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data from key: 'lfpdata'\n",
      "Data type: float64\n",
      "Original shape: (30000200, 23)\n",
      "HDF5 detected. Transposing from (30000200, 23) to (23, 30000200)\n",
      "File '/Volumes/kovi ssd/egyetem/7.felev-szakdoga/THUMB/patients/epi52_sleep/epi52_01_sleep_2_thumb_1.mat' loaded successfully!\n",
      "Final data shape: (23, 30000200) (channels x samples)\n",
      "\n",
      "Loaded data shape: (23, 30000200)\n",
      "Data type: float32\n",
      "Cleaned file path: /Volumes/kovi ssd/egyetem/7.felev-szakdoga/THUMB/patients/epi52_sleep/epi52_01_sleep_2_thumb_1.mat\n"
     ]
    }
   ],
   "source": [
    "dir_path = []\n",
    "loaded_data = None\n",
    "cleaned_path = None  # Declare globally\n",
    "\n",
    "def load_mat_file(file_path):\n",
    "    try:\n",
    "        # Try loading with scipy first (for MATLAB < v7.3)\n",
    "        mat_data = scipy.io.loadmat(file_path)\n",
    "        is_hdf5 = False\n",
    "    except NotImplementedError:\n",
    "        # File is MATLAB v7.3 format, use h5py\n",
    "        mat_data = h5py.File(file_path, 'r')\n",
    "        is_hdf5 = True\n",
    "    \n",
    "    return mat_data, is_hdf5\n",
    "\n",
    "def extract_data_from_mat(mat_data, is_hdf5=False):\n",
    "    if is_hdf5:\n",
    "        # HDF5 format (MATLAB v7.3)\n",
    "        data_keys = [key for key in mat_data.keys() if not key.startswith('#')]\n",
    "    else:\n",
    "        # Older MATLAB format\n",
    "        data_keys = [key for key in mat_data.keys() if not key.startswith('__')]\n",
    "    \n",
    "    if len(data_keys) == 0:\n",
    "        raise ValueError(\"No data arrays found in .mat file.\")\n",
    "    \n",
    "    elif len(data_keys) == 1:\n",
    "        # Single array found, use it directly\n",
    "        selected_key = data_keys[0]\n",
    "        if is_hdf5:\n",
    "            eeg_data = np.array(mat_data[selected_key])\n",
    "        else:\n",
    "            eeg_data = mat_data[selected_key]\n",
    "        print(f\"Loaded data from key: '{selected_key}'\")\n",
    "    \n",
    "    else:\n",
    "        # Multiple arrays found, prompt user to select\n",
    "        print(f\"\\nMultiple data arrays found in .mat file:\")\n",
    "        for i, key in enumerate(data_keys, 1):\n",
    "            if is_hdf5:\n",
    "                shape = mat_data[key].shape\n",
    "                dtype = mat_data[key].dtype\n",
    "            else:\n",
    "                shape = mat_data[key].shape\n",
    "                dtype = mat_data[key].dtype\n",
    "            print(f\"  {i}. '{key}' - Shape: {shape}, Type: {dtype}\")\n",
    "        \n",
    "        selection = int(input(\"\\nSelect the data array by number: \").strip())\n",
    "        if selection < 1 or selection > len(data_keys):\n",
    "            raise ValueError(\"Invalid selection.\")\n",
    "        \n",
    "        selected_key = data_keys[selection - 1]\n",
    "        if is_hdf5:\n",
    "            eeg_data = np.array(mat_data[selected_key])\n",
    "        else:\n",
    "            eeg_data = mat_data[selected_key]\n",
    "        print(f\"Loaded data from key: '{selected_key}'\")\n",
    "    \n",
    "    return eeg_data\n",
    "\n",
    "def load_eeg_data(file_path, num_channels=None):\n",
    "    try:\n",
    "        if not os.path.isfile(file_path):\n",
    "            raise FileNotFoundError(f\"The file '{file_path}' does not exist.\")\n",
    "        \n",
    "        if file_path.endswith('.bin'):\n",
    "            if num_channels is None:\n",
    "                raise ValueError(\"Number of channels must be specified for .bin files.\")\n",
    "            with open(file_path, 'rb') as f:\n",
    "                eeg_data = np.fromfile(f, dtype=np.int16)\n",
    "                eeg_data = eeg_data.reshape((-1, num_channels)).T\n",
    "        \n",
    "        elif file_path.endswith('.npy'):\n",
    "            eeg_data = np.load(file_path).T\n",
    "            num_channels = eeg_data.shape[0]\n",
    "        \n",
    "        elif file_path.endswith('.mat'):\n",
    "            # Load .mat file (handles both v7.3 and older formats)\n",
    "            mat_data, is_hdf5 = load_mat_file(file_path)\n",
    "            \n",
    "            try:\n",
    "                eeg_data = extract_data_from_mat(mat_data, is_hdf5)\n",
    "            finally:\n",
    "                # Close HDF5 file if opened\n",
    "                if is_hdf5:\n",
    "                    mat_data.close()\n",
    "            \n",
    "            print(f\"Data type: {eeg_data.dtype}\")\n",
    "            print(f\"Original shape: {eeg_data.shape}\")\n",
    "            \n",
    "            # Handle data shape - ensure it's 2D (channels x samples)\n",
    "            if eeg_data.ndim == 1:\n",
    "                eeg_data = eeg_data.reshape(1, -1)\n",
    "                print(\"Reshaped 1D data to (1, samples)\")\n",
    "            elif eeg_data.ndim == 2:\n",
    "                # HDF5 files often need transposing\n",
    "                if is_hdf5:\n",
    "                    # HDF5 stores data in transposed format by default\n",
    "                    print(f\"HDF5 detected. Transposing from {eeg_data.shape} to {eeg_data.T.shape}\")\n",
    "                    eeg_data = eeg_data.T\n",
    "                \n",
    "                # Check if further transpose is needed (samples x channels -> channels x samples)\n",
    "                if eeg_data.shape[0] > eeg_data.shape[1]:\n",
    "                    print(f\"Data shape is {eeg_data.shape}, assuming (samples x channels)\")\n",
    "                    response = input(\"Transpose to (channels x samples)? (y/n): \").strip().lower()\n",
    "                    if response == 'y':\n",
    "                        eeg_data = eeg_data.T\n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported data dimensions: {eeg_data.ndim}D. Expected 1D or 2D array.\")\n",
    "            \n",
    "            num_channels = eeg_data.shape[0]\n",
    "        \n",
    "        else:\n",
    "            raise ValueError(\"Unsupported file format. Only .bin, .npy, and .mat are supported.\")\n",
    "\n",
    "        print(f\"File '{file_path}' loaded successfully!\")\n",
    "        print(f\"Final data shape: {eeg_data.shape} (channels x samples)\")\n",
    "        return eeg_data\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading file '{file_path}': {e}\")\n",
    "        return None\n",
    "\n",
    "def main():\n",
    "    global dir_path, loaded_data, cleaned_path\n",
    "\n",
    "    # Prompt for the full file path\n",
    "    file_path = input(\"Enter the full path to the EEG file (.bin, .npy, or .mat): \").strip().strip(\"'\\\"\")\n",
    "\n",
    "    # Validate file type and prompt for channels if needed\n",
    "    if file_path.endswith('.bin'):\n",
    "        try:\n",
    "            num_channels = int(input(\"Enter the number of channels (required for .bin files): \").strip())\n",
    "        except ValueError:\n",
    "            print(\"Invalid input. Number of channels must be an integer.\")\n",
    "            return\n",
    "    else:\n",
    "        num_channels = None\n",
    "\n",
    "    # Load the data\n",
    "    loaded_data = load_eeg_data(file_path, num_channels)\n",
    "    \n",
    "    if loaded_data is not None:\n",
    "        # Convert to float32\n",
    "        loaded_data = loaded_data.astype(np.float32)\n",
    "        \n",
    "        # Save the file path for later reference\n",
    "        cleaned_path = file_path.replace(\"\\\\\", \"/\")\n",
    "        dir_path.append(cleaned_path)\n",
    "\n",
    "        # Print data and path details\n",
    "        print(f\"\\nLoaded data shape: {loaded_data.shape}\")\n",
    "        print(f\"Data type: {loaded_data.dtype}\")\n",
    "        print(f\"Cleaned file path: {cleaned_path}\")\n",
    "    else:\n",
    "        print(\"No data loaded.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d838fbe1-7073-40be-98d6-4434c09b4df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Do you want to perform outlier curation? (y/n):  n\n"
     ]
    }
   ],
   "source": [
    "def remove_outliers(samples, curation_needed=True):\n",
    "    if not curation_needed:\n",
    "        return samples, np.array([])  # No curation needed, return the original data and empty outlier indices\n",
    "\n",
    "    # Calculate the first and third quartiles\n",
    "    Q1 = np.percentile(samples, 1, axis=0)\n",
    "    Q3 = np.percentile(samples, 99, axis=0)\n",
    "\n",
    "    # Calculate the interquartile range (IQR)\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    # Set a threshold for outlier detection (e.g., 1.5 times the IQR)\n",
    "    threshold_factor = 1.5\n",
    "    lower_thresholds = Q1 - threshold_factor * IQR\n",
    "    upper_thresholds = Q3 + threshold_factor * IQR\n",
    "\n",
    "    outlier_indices = []\n",
    "    curated_data = np.copy(samples)\n",
    "\n",
    "    for channel in range(samples.shape[1]):\n",
    "        channel_indices_below = np.where(samples[:, channel] < lower_thresholds[channel])[0]\n",
    "        channel_indices_above = np.where(samples[:, channel] > upper_thresholds[channel])[0]\n",
    "        channel_indices = list(set(channel_indices_below) | set(channel_indices_above))\n",
    "\n",
    "        for index in channel_indices:\n",
    "            # Set the 400 timepoints before and after outlier to zero\n",
    "            start_index = max(0, index - 400)\n",
    "            end_index = min(samples.shape[0] - 1, index + 400)\n",
    "            curated_data[start_index:end_index + 1, channel] = 0\n",
    "\n",
    "        outlier_indices.append(sorted(channel_indices))\n",
    "\n",
    "    outlier_indices = np.array(sorted(list(set(item for sublist in outlier_indices for item in sublist))))\n",
    "\n",
    "    return curated_data, outlier_indices\n",
    "\n",
    "# Ask the user if they want to perform curation\n",
    "curation_decision = input(\"Do you want to perform outlier curation? (y/n): \").lower()\n",
    "\n",
    "if curation_decision == 'y':\n",
    "    loaded_data, outlier_indices = remove_outliers(loaded_data)\n",
    "else:\n",
    "    loaded_data = loaded_data\n",
    "    outlier_indices = np.array([])\n",
    "\n",
    "# Define filtering functions\n",
    "def apply_hamming_filter(input_data, sampling_rate, channels_to_exclude=None, double=False):\n",
    "    center_coefficient = 0.54\n",
    "    side_coefficient = 0.23\n",
    "    filter_kernel = np.array([side_coefficient, center_coefficient, side_coefficient])\n",
    "\n",
    "    # Ensure the input_data is longer than the kernel\n",
    "    if input_data.shape[0] < len(filter_kernel):\n",
    "        raise ValueError(\"Input data must be longer than the kernel size\")\n",
    "\n",
    "    hamming_data = np.apply_along_axis(\n",
    "        lambda x: np.convolve(x, filter_kernel, mode='same'),\n",
    "        axis=0,\n",
    "        arr=input_data\n",
    "    )\n",
    "\n",
    "    if double:\n",
    "        hamming_data = np.apply_along_axis(\n",
    "            lambda x: np.convolve(x, filter_kernel, mode='same'),\n",
    "            axis=0,\n",
    "            arr=hamming_data\n",
    "        )\n",
    "    \n",
    "    if channels_to_exclude:\n",
    "        hamming_data[:, channels_to_exclude] = input_data[:, channels_to_exclude]\n",
    "\n",
    "    return hamming_data\n",
    "\n",
    "def butter_bandpass(lowcut, highcut, fs, order=4):\n",
    "    nyquist = 0.5 * fs\n",
    "    low = lowcut / nyquist if lowcut is not None else None\n",
    "    high = highcut / nyquist if highcut is not None else None\n",
    "\n",
    "    if lowcut is not None and highcut is not None:\n",
    "        sos = butter(order, [low, high], btype='band', output='sos')\n",
    "    elif lowcut is None and highcut is not None:\n",
    "        sos = butter(order, high, btype='low', output='sos')\n",
    "    elif lowcut is not None and highcut is None:\n",
    "        sos = butter(order, low, btype='high', output='sos')\n",
    "    else:\n",
    "        raise ValueError(\"At least one of lowcut or highcut must be provided.\")\n",
    "\n",
    "    return sos\n",
    "\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=4):\n",
    "    num_channels = data.shape[0]\n",
    "    filtered_data = np.zeros_like(data)\n",
    "\n",
    "    for i in range(num_channels):\n",
    "        sos = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "        filtered_data[i, :] = sosfiltfilt(sos, data[i, :])\n",
    "\n",
    "    return filtered_data\n",
    "\n",
    "def preprocess_data(raw_data, fs):\n",
    "    # Apply bandpass filter\n",
    "    bandpassed_data = butter_bandpass_filter(raw_data, 1, 30, fs)\n",
    "\n",
    "    # Apply Hamming filter\n",
    "    preprocessed_data = apply_hamming_filter(bandpassed_data, sampling_rate=fs_resampled, double=False)\n",
    "    \n",
    "    return preprocessed_data\n",
    "\n",
    "def compute_csd(data, spacing=1.0, data_is_first_derivative=False):\n",
    "    d = np.asarray(data, dtype=np.float64)\n",
    "    csd = np.zeros_like(d)\n",
    "\n",
    "    if d.size == 0:\n",
    "        return csd\n",
    "\n",
    "    if data_is_first_derivative:\n",
    "        if d.shape[0] == 1:\n",
    "            csd[:] = 0.0\n",
    "            return csd\n",
    "\n",
    "        csd[1:, :] = (d[1:, :] - d[:-1, :]) / spacing\n",
    "        csd[0, :] = csd[1, :]\n",
    "        csd = csd / spacing\n",
    "    else:\n",
    "        nchan = d.shape[0]\n",
    "        if nchan < 3:\n",
    "            csd[:] = 0.0\n",
    "            return csd\n",
    "\n",
    "        csd[1:-1, :] = (d[:-2, :] - 2.0 * d[1:-1, :] + d[2:, :]) / (spacing ** 2)\n",
    "        csd[0, :] = csd[1, :]\n",
    "        csd[-1, :] = csd[-2, :]\n",
    "\n",
    "    return csd\n",
    "\n",
    "window_duration = 10\n",
    "\n",
    "t = loaded_data.shape[1]\n",
    "num_channels = loaded_data.shape[0]\n",
    "fs = 20000 #recording freq\n",
    "fs_resampled = 2000\n",
    "fs_resampled_high = 5000\n",
    "resampled_data_high = loaded_data[:, ::4]\n",
    "resampled_data = loaded_data[:, ::10]\n",
    "resamp_data = preprocess_data(resampled_data, fs_resampled)\n",
    "plot_height_inches = min(6 * num_channels, 9)  \n",
    "plot_width_inches = 14  \n",
    "figsize = (plot_width_inches, plot_height_inches)\n",
    "INT16_TO_UV = 1 #0.30518 if in int16 change to this value\n",
    "max_data = np.max(loaded_data)\n",
    "min_data = np.min(loaded_data)\n",
    "span = max_data - min_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "474588dc-30b4-4f25-ba87-7b8c63029fc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4d70db0ba97496ab2dc09eac19d9ded",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatText(value=10.0, description='Window Duration'), Text(value='', description='Hidden…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a753167cdc4846fd88cb7619e6cba057",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Checkbox(value=False, description='Fast Scroll')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4533421727544651b5cc2e252614b87e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='warning', description='Polychrome', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03cd20cdbd9149b5886d870154ab7dc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='info', description='Take a Snapshot', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87dd93d89c094acdaf9d4bf3dd09f790",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='success', description='Save Filter Settings', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e2ebedb61104be68fbd9d3c4f53fb2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='info', description='New Window', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "444c7a593129434fa337a94c27af8c73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Checkbox(value=False, description='Noisy Data Mode')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "390d8300e07244b4af548a2ea0150dc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Checkbox(value=False, description='Apply CSD (for traces)')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64e304789dd447cdbb7b2979a320929d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Checkbox(value=False, description='Show CSD Heatmap')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e796784fdd04d9e9dcf6a4cd4ec7549",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Checkbox(value=True, description='Input is 1st-derivative')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0f28762c8ff4dd6902327b542abb8a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatText(value=1.0, description='Channel Spacing')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b17c8bb40de466488d6cd69176f3510",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='Noisy Intervals: []')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bb2694e089840ed8b015ee769168e25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='danger', description='Reset Noisy Intervals', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-24 19:19:43.637 python3.13[84592:26391550] +[IMKClient subclass]: chose IMKClient_Modern\n"
     ]
    }
   ],
   "source": [
    "start_time = 0\n",
    "filter_settings = {}\n",
    "snapshot_counter = 1\n",
    "scale_amplitude = 1.0\n",
    "use_monochrome = True  # Toggle for Monochrome/Gradient\n",
    "window_duration_str = '10'\n",
    "noisy_intervals = []\n",
    "is_noisy_mode = False\n",
    "current_interval = []\n",
    "noisy_mode_checkbox = widgets.Checkbox(value=False, description='Noisy Data Mode')\n",
    "noisy_intervals_label = widgets.Label(value=\"Noisy Intervals: []\")\n",
    "\n",
    "def calculate_starting_amplitude(data, multiplier=0.5):\n",
    "    return (1.0 / np.max(np.abs(data))) * multiplier\n",
    "\n",
    "def toggle_monochrome(event):\n",
    "    global use_monochrome\n",
    "    use_monochrome = not use_monochrome\n",
    "    plt.clf()  # Clear the current plot\n",
    "    visualize_eeg_data(window_duration_text.value, hidden_channels_text.value,\n",
    "                       apply_hamming=apply_hamming_checkbox.value,\n",
    "                       apply_double_hamming=apply_double_hamming_checkbox.value,\n",
    "                       apply_bandpass=apply_bandpass_checkbox.value,\n",
    "                       lowcut=lowcut_text.value,\n",
    "                       highcut=highcut_text.value,\n",
    "                       scale_amplitude=scale_amplitude)\n",
    "    plt.draw()\n",
    "\n",
    "def toggle_noisy_mode(change):\n",
    "    global is_noisy_mode\n",
    "    is_noisy_mode = change.new\n",
    "    if not is_noisy_mode:\n",
    "        finalize_noisy_interval()\n",
    "noisy_mode_checkbox.observe(toggle_noisy_mode, names='value')\n",
    "\n",
    "# Finalize the current noisy interval if any\n",
    "def finalize_noisy_interval():\n",
    "    global current_interval, noisy_intervals\n",
    "    if len(current_interval) == 2:\n",
    "        # Convert relative interval to absolute time\n",
    "        noisy_intervals.append((round(current_interval[0], 2), round(current_interval[1], 2)))\n",
    "        current_interval = []\n",
    "        update_noisy_intervals_label()\n",
    "\n",
    "# Update the noisy intervals label\n",
    "def update_noisy_intervals_label():\n",
    "    noisy_intervals_label.value = f\"Noisy Intervals: {noisy_intervals}\"\n",
    "\n",
    "def visualize_eeg_data(window_duration_str, hidden_channels_str, apply_hamming=False, apply_double_hamming=False, apply_bandpass=False, lowcut=None, highcut=None, scale_amplitude=1.0):\n",
    "    plt.clf()\n",
    "\n",
    "    global resampled_data, resampled_data_high, fs_resampled, fs_resampled_high, num_channels, window_duration, start_time, filter_settings, use_monochrome\n",
    "    window_duration = float(window_duration_str)\n",
    "    window_start = int(start_time * fs_resampled)\n",
    "    window_end = window_start + int(window_duration * fs_resampled)\n",
    "\n",
    "    hidden_channels = []\n",
    "    if hidden_channels_str.strip() and hidden_channels_str != '':\n",
    "        hidden_channels = parse_hidden_channels(hidden_channels_str)\n",
    "\n",
    "    selected_channels = np.array([channel for channel in range(1, num_channels + 1) if channel not in hidden_channels])\n",
    "    num_visible_channels = len(selected_channels)\n",
    "\n",
    "    if use_monochrome:\n",
    "        plt.gca().set_facecolor('white')\n",
    "        text_color = 'white'\n",
    "        grid_color = 'gray'\n",
    "        line_color = '#e36414'\n",
    "    else:\n",
    "        plt.gca().set_facecolor('black')\n",
    "        text_color = 'black'\n",
    "        grid_color = 'white'\n",
    "        line_color = None\n",
    "\n",
    "    if num_visible_channels > 0:\n",
    "        # Convert lowcut and highcut to float only if they are valid, otherwise set them to None\n",
    "        try:\n",
    "            lowcut = float(lowcut) if lowcut not in [None, ''] else None\n",
    "            highcut = float(highcut) if highcut not in [None, ''] else None\n",
    "        except ValueError:\n",
    "            print(\"Invalid input for lowcut or highcut. Please enter valid numerical values.\")\n",
    "            return\n",
    "\n",
    "        # Choose appropriate resampled data if highcut > nyquist for the lower-resampled stream\n",
    "        nyquist_freq = fs_resampled / 2\n",
    "        if highcut is not None and highcut > nyquist_freq:\n",
    "            print(f\"Highcut frequency {highcut} exceeds Nyquist frequency {nyquist_freq}.\")\n",
    "            data_to_visualize = resampled_data_high[selected_channels - 1, window_start:window_end] * scale_amplitude\n",
    "        else:\n",
    "            data_to_visualize = resampled_data[selected_channels - 1, window_start:window_end] * scale_amplitude\n",
    "\n",
    "        if apply_hamming or apply_double_hamming:\n",
    "            data_to_visualize = apply_hamming_filter(data_to_visualize, fs_resampled, double=apply_double_hamming)\n",
    "\n",
    "        if apply_bandpass:\n",
    "            try:\n",
    "                if lowcut is not None or highcut is not None:\n",
    "                    data_to_visualize = butter_bandpass_filter(data_to_visualize, lowcut, highcut, fs_resampled)\n",
    "            except ValueError:\n",
    "                print(\"Switching from 2 kHz downsampled data to 5 kHz.\")\n",
    "\n",
    "        # If user requested a CSD heatmap, compute CSD and plot heatmap instead of traces\n",
    "        if 'csd_heatmap_checkbox' in globals() and csd_heatmap_checkbox.value:\n",
    "            spacing = float(channel_spacing_text.value) if ('channel_spacing_text' in globals() and channel_spacing_text.value is not None) else 1.0\n",
    "            is_first_deriv = ('csd_is_gradient_checkbox' in globals() and csd_is_gradient_checkbox.value)\n",
    "\n",
    "            # compute CSD (channels x time)\n",
    "            csd_data = compute_csd(data_to_visualize, spacing=spacing, data_is_first_derivative=is_first_deriv)\n",
    "\n",
    "            # normalize symmetrically around zero for diverging colormap\n",
    "            if csd_data.size > 0:\n",
    "                vmax = np.nanmax(np.abs(csd_data))\n",
    "                if vmax == 0:\n",
    "                    vmax = 1.0\n",
    "            else:\n",
    "                vmax = 1.0\n",
    "            norm = Normalize(vmin=-vmax, vmax=vmax)\n",
    "\n",
    "            # Show CSD heatmap: channels on y, time on x\n",
    "            im = plt.imshow(csd_data, aspect='auto', cmap='RdBur', norm=norm, origin='lower',\n",
    "                            extent=[0, window_duration, selected_channels[0], selected_channels[-1]])\n",
    "            plt.colorbar(im, label='CSD (arb. units)')\n",
    "            plt.ylabel('Channel')\n",
    "            # simplify y ticks: show channel numbers\n",
    "            try:\n",
    "                plt.yticks(np.linspace(selected_channels[0], selected_channels[-1], min(10, num_visible_channels)).astype(int))\n",
    "            except Exception:\n",
    "                pass\n",
    "        else:\n",
    "            # Optionally apply CSD to the traces (if csd_apply_checkbox exists and is checked).\n",
    "            # This makes the stacked traces show CSD values instead of the original data rows.\n",
    "            if 'csd_apply_checkbox' in globals() and csd_apply_checkbox.value:\n",
    "                spacing = float(channel_spacing_text.value) if ('channel_spacing_text' in globals() and channel_spacing_text.value is not None) else 1.0\n",
    "                is_first_deriv = ('csd_is_gradient_checkbox' in globals() and csd_is_gradient_checkbox.value)\n",
    "                # compute CSD and replace data_to_visualize with it (keeps same channels x time shape)\n",
    "                try:\n",
    "                    data_to_visualize = compute_csd(data_to_visualize, spacing=spacing, data_is_first_derivative=is_first_deriv)\n",
    "                except Exception as e:\n",
    "                    print(\"Error computing CSD for traces:\", e)\n",
    "                    # fallback to original data_to_visualize\n",
    "\n",
    "            # Draw stacked traces as before (either potentials/gradient or CSD if csd_apply_checkbox was true)\n",
    "            span = 5000\n",
    "            colors = plt.cm.tab20(np.linspace(0, 1, num_visible_channels)) if not use_monochrome else ['#0f4c5c'] * num_visible_channels\n",
    "            for i, (channel_data, color) in enumerate(zip(data_to_visualize, colors)):\n",
    "                time = np.linspace(window_start / fs_resampled, window_end / fs_resampled, len(channel_data))\n",
    "                plt.plot(time - start_time, channel_data + (num_visible_channels - 1 - i) * span, color=color, alpha=0.95, linewidth=0.5)\n",
    "\n",
    "            plt.ylim(-span, num_visible_channels * span)\n",
    "            plt.yticks(np.arange(0, num_visible_channels) * span, reversed(selected_channels))\n",
    "    else:\n",
    "        plt.ylim(0, 1)\n",
    "\n",
    "    for start, end in noisy_intervals:\n",
    "        highlight_start = max(start, start_time)\n",
    "        highlight_end = min(end, start_time + window_duration)\n",
    "        if highlight_start < highlight_end:\n",
    "            plt.axvspan(highlight_start - start_time, highlight_end - start_time, color='red', alpha=0.3)\n",
    "\n",
    "    plt.xticks(np.linspace(0, window_duration, 11), np.round(np.linspace(start_time, start_time + window_duration, 11), 2))\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.grid(True, axis='x', linestyle='--', color='#e36414', alpha=0.5)\n",
    "    plt.tight_layout()\n",
    "    plt.gca().yaxis.set_ticks_position('both')\n",
    "    plt.tick_params(axis='y', labelleft=True, labelright=True)\n",
    "    plt.subplots_adjust(left=0.05, right=0.95)\n",
    "    plt.show()\n",
    "\n",
    "    fig = plt.gcf().number\n",
    "    if fig in filter_settings:\n",
    "        settings = filter_settings[fig]\n",
    "        apply_hamming_checkbox.value = settings['apply_hamming']\n",
    "        apply_double_hamming_checkbox.value = settings['apply_double_hamming']\n",
    "        apply_bandpass_checkbox.value = settings['apply_bandpass']\n",
    "        lowcut_text.value = settings['lowcut'] if settings['lowcut'] is not None else ''\n",
    "        highcut_text.value = settings['highcut'] if settings['highcut'] is not None else ''\n",
    "\n",
    "def save_filter_settings(_):\n",
    "    global filter_settings\n",
    "    fig = plt.gcf().number\n",
    "    filter_settings[fig] = {\n",
    "        'apply_hamming': apply_hamming_checkbox.value,\n",
    "        'apply_double_hamming': apply_double_hamming_checkbox.value,\n",
    "        'apply_bandpass': apply_bandpass_checkbox.value,\n",
    "        'lowcut': lowcut_text.value,\n",
    "        'highcut': highcut_text.value,\n",
    "        'scale_amplitude': scale_amplitude\n",
    "    }\n",
    "    print(f\"Filter settings saved for figure {fig}.\")\n",
    "\n",
    "def parse_hidden_channels(hidden_channels_str):\n",
    "    hidden_channels = set()\n",
    "    ranges = hidden_channels_str.split(',')\n",
    "    for r in ranges:\n",
    "        try:\n",
    "            if '-' in r:\n",
    "                start, end = r.split('-')\n",
    "                hidden_channels.update(range(int(start), int(end) + 1))\n",
    "            else:\n",
    "                hidden_channels.add(int(r))\n",
    "        except ValueError:\n",
    "            pass\n",
    "    return list(hidden_channels)\n",
    "\n",
    "def save_snapshot(_):\n",
    "    global snapshot_counter, filter_settings\n",
    "    snap_path = os.path.join(cleaned_path[:-4] + f'_overall_window{snapshot_counter}.svg')\n",
    "    filter_settings[snap_path] = {\n",
    "        'apply_hamming': apply_hamming_checkbox.value,\n",
    "        'apply_double_hamming': apply_double_hamming_checkbox.value,\n",
    "        'apply_bandpass': apply_bandpass_checkbox.value,\n",
    "        'lowcut': lowcut_text.value,\n",
    "        'highcut': highcut_text.value,\n",
    "    }\n",
    "    snapshot_counter += 1\n",
    "    plt.savefig(snap_path, bbox_inches='tight')\n",
    "\n",
    "def on_key(event):\n",
    "    global start_time\n",
    "\n",
    "    if event.key == 'left':\n",
    "        start_time -= round(window_duration * 0.2, 2) if not scroll_fast_checkbox.value else window_duration\n",
    "        start_time = max(0, start_time)\n",
    "    elif event.key == 'right':\n",
    "        start_time += round(window_duration * 0.2, 2) if not scroll_fast_checkbox.value else window_duration\n",
    "        start_time = min(t - window_duration, start_time)\n",
    "\n",
    "    for fig in plt.get_fignums():\n",
    "        plt.figure(fig)\n",
    "        visualize_eeg_data(window_duration_text.value,\n",
    "                           hidden_channels_text.value,\n",
    "                           apply_hamming=apply_hamming_checkbox.value,\n",
    "                           apply_double_hamming=apply_double_hamming_checkbox.value,\n",
    "                           apply_bandpass=apply_bandpass_checkbox.value,\n",
    "                           lowcut=lowcut_text.value if lowcut_text.value != '' else None,\n",
    "                           highcut=highcut_text.value if highcut_text.value != '' else None)\n",
    "        plt.draw()\n",
    "\n",
    "def on_arrow_key(event):\n",
    "    global scale_amplitude\n",
    "    if event.key == 'up':\n",
    "        scale_amplitude *= 1.5\n",
    "    elif event.key == 'down':\n",
    "        scale_amplitude /= 1.5\n",
    "    visualize_eeg_data(window_duration_text.value,\n",
    "                       hidden_channels_text.value,\n",
    "                       apply_hamming=apply_hamming_checkbox.value,\n",
    "                       apply_double_hamming=apply_double_hamming_checkbox.value,\n",
    "                       apply_bandpass=apply_bandpass_checkbox.value,\n",
    "                       lowcut=lowcut_text.value,\n",
    "                       highcut=highcut_text.value,\n",
    "                       scale_amplitude=scale_amplitude)\n",
    "    plt.draw()\n",
    "\n",
    "def reset_noisy_intervals(change):\n",
    "    global noisy_intervals, current_interval\n",
    "    noisy_intervals = []\n",
    "    current_interval = []\n",
    "    update_noisy_intervals_label()\n",
    "    print(\"Noisy intervals have been reset.\")\n",
    "\n",
    "def on_click(event):\n",
    "    global current_interval, is_noisy_mode, start_time\n",
    "    if is_noisy_mode:\n",
    "        if len(current_interval) == 0:\n",
    "            # Mark the start of the noisy interval (absolute time)\n",
    "            current_interval.append(event.xdata + start_time)\n",
    "            print(f\"Noisy interval start marked at: {event.xdata + start_time:.2f} seconds\")\n",
    "        elif len(current_interval) == 1:\n",
    "            # Mark the end of the noisy interval (absolute time)\n",
    "            current_interval.append(event.xdata + start_time)\n",
    "            print(f\"Noisy interval end marked at: {event.xdata + start_time:.2f} seconds\")\n",
    "            finalize_noisy_interval()\n",
    "\n",
    "# Attach the click event to the matplotlib figure\n",
    "plt.gcf().canvas.mpl_connect('button_press_event', on_click)\n",
    "\n",
    "reset_button = widgets.Button(description='Reset Noisy Intervals', button_style='danger')\n",
    "reset_button.on_click(reset_noisy_intervals)\n",
    "\n",
    "def reset_scale_amplitude():\n",
    "    global scale_amplitude\n",
    "    scale_amplitude = calculate_starting_amplitude(resampled_data, initial_scale_multiplier)\n",
    "\n",
    "def new_window(_):\n",
    "    global resampled_data, fs_resampled, num_channels, start_time, scale_amplitude\n",
    "\n",
    "    window_duration_text_new = widgets.FloatText(value=window_duration_text.value, description='Window Duration')\n",
    "    hidden_channels_text_new = widgets.Text(value=hidden_channels_text.value, description='Hidden Channels')\n",
    "\n",
    "    apply_hamming_checkbox_new = widgets.Checkbox(value=apply_hamming_checkbox.value, description='Apply Hamming')\n",
    "    apply_double_hamming_checkbox_new = widgets.Checkbox(value=apply_double_hamming_checkbox.value, description='Apply Double Hamming')\n",
    "    apply_bandpass_checkbox_new = widgets.Checkbox(value=apply_bandpass_checkbox.value, description='Apply Bandpass')\n",
    "    lowcut_text_new = widgets.FloatText(value=lowcut_text.value, description='Lowcut')\n",
    "    highcut_text_new = widgets.FloatText(value=highcut_text.value, description='Highcut')\n",
    "\n",
    "    plt.figure()\n",
    "\n",
    "    plt.gcf().canvas.mpl_connect('key_press_event', on_key)\n",
    "    plt.gcf().canvas.mpl_connect('key_press_event', on_arrow_key)\n",
    "\n",
    "    initial_scale_amplitude = calculate_starting_amplitude(resampled_data, initial_scale_multiplier)\n",
    "\n",
    "    visualize_eeg_data(window_duration_text_new.value,\n",
    "                       hidden_channels_text_new.value,\n",
    "                       apply_hamming=apply_hamming_checkbox_new.value,\n",
    "                       apply_double_hamming=apply_double_hamming_checkbox_new.value,\n",
    "                       apply_bandpass=apply_bandpass_checkbox_new.value,\n",
    "                       lowcut=lowcut_text_new.value,\n",
    "                       highcut=highcut_text_new.value)\n",
    "\n",
    "    snapshot_button_new = widgets.Button(description='Take a Snapshot', button_style='info')\n",
    "    snapshot_button_new.on_click(save_snapshot)\n",
    "    display(snapshot_button_new)\n",
    "    display(window_duration_text_new)\n",
    "    display(hidden_channels_text_new)\n",
    "\n",
    "    display(apply_hamming_checkbox_new)\n",
    "    display(apply_double_hamming_checkbox_new)\n",
    "    display(apply_bandpass_checkbox_new)\n",
    "    display(lowcut_text_new)\n",
    "    display(highcut_text_new)\n",
    "\n",
    "window_duration_text = widgets.FloatText(value='10', description='Window Duration')\n",
    "hidden_channels_text = widgets.Text(value='', description='Hidden Channels')\n",
    "apply_hamming_checkbox = widgets.Checkbox(value=False, description='Apply Hamming')\n",
    "apply_double_hamming_checkbox = widgets.Checkbox(value=False, description='Apply Double Hamming')\n",
    "apply_bandpass_checkbox = widgets.Checkbox(value=False, description='Apply Bandpass')\n",
    "lowcut_text = widgets.Text(value='', placeholder='Lowcut (Hz)', description='Lowcut:')\n",
    "highcut_text = widgets.Text(value='', placeholder='Highcut (Hz)', description='Highcut:')\n",
    "scroll_fast_checkbox = widgets.Checkbox(value=False, description='Fast Scroll')\n",
    "csd_apply_checkbox = widgets.Checkbox(value=False, description='Apply CSD (for traces)')\n",
    "csd_heatmap_checkbox = widgets.Checkbox(value=False, description='Show CSD Heatmap')\n",
    "csd_is_gradient_checkbox = widgets.Checkbox(value=True, description='Input is 1st-derivative')\n",
    "channel_spacing_text = widgets.FloatText(value=1.0, description='Channel Spacing')\n",
    "\n",
    "# Adjust the function to handle key release event to allow empty input\n",
    "def on_lowcut_change(change):\n",
    "    if change['new'] == '':\n",
    "        lowcut_text.value = ''  # Allow the input to be empty\n",
    "\n",
    "def on_highcut_change(change):\n",
    "    if change['new'] == '':\n",
    "        highcut_text.value = ''  # Allow the input to be empty\n",
    "\n",
    "# Attach the change events\n",
    "lowcut_text.observe(on_lowcut_change, names='value')\n",
    "highcut_text.observe(on_highcut_change, names='value')\n",
    "\n",
    "plt.gcf().canvas.mpl_connect('key_press_event', on_key)\n",
    "plt.gcf().canvas.mpl_connect('key_press_event', on_arrow_key)\n",
    "\n",
    "interact(visualize_eeg_data,\n",
    "         window_duration_str=window_duration_text,\n",
    "         hidden_channels_str=hidden_channels_text,\n",
    "         apply_hamming=apply_hamming_checkbox,\n",
    "         apply_double_hamming=apply_double_hamming_checkbox,\n",
    "         apply_bandpass=apply_bandpass_checkbox,\n",
    "         lowcut=lowcut_text,\n",
    "         highcut=highcut_text)\n",
    "\n",
    "snapshot_button = widgets.Button(description='Take a Snapshot', button_style='info')\n",
    "snapshot_button.on_click(save_snapshot)\n",
    "\n",
    "save_filter_settings_button = widgets.Button(description='Save Filter Settings', button_style='success')\n",
    "save_filter_settings_button.on_click(save_filter_settings)\n",
    "\n",
    "new_window_button = widgets.Button(description='New Window', button_style='info')\n",
    "new_window_button.on_click(new_window)\n",
    "monochrome_button = widgets.Button(description='Polychrome', button_style='warning')\n",
    "monochrome_button.on_click(toggle_monochrome)\n",
    "\n",
    "# Display the button\n",
    "display(scroll_fast_checkbox)\n",
    "display(monochrome_button)\n",
    "display(snapshot_button)\n",
    "display(save_filter_settings_button)\n",
    "display(new_window_button)\n",
    "display(noisy_mode_checkbox)\n",
    "\n",
    "display(csd_apply_checkbox)\n",
    "display(csd_heatmap_checkbox)\n",
    "display(csd_is_gradient_checkbox)\n",
    "display(channel_spacing_text)\n",
    "display(noisy_intervals_label)\n",
    "display(reset_button)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22ba5ad8-f220-467e-9513-8931288c499c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the channels to plot (comma-separated or interval):  4-10\n",
      "Select the target channel:  6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4495d3d44822418a9cd175d51d10bbb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Export to EV2', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6d80a43da504c5f883403679659e002",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Text(value='4-10', description='Channels to Plot'), Text(value='6', description='Target …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c41d2aea3104d5493fa4dc059c894ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Peak Mode', options=('Positive', 'Negative'), value='Positive')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88062e96e1f048bc855207fdb887641a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='info', description='Take a Snapshot', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "313fdbfca39c45a9b60cffea138d753c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Checkbox(value=False, description='Fast Scroll', indent=False)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "accd06f37894408f85482f8b8cb33b0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Reset Detection', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_time = 0\n",
    "window_duration = 10  # Default window duration is 10 seconds\n",
    "channel_thresholds = {}\n",
    "\n",
    "# Get channels to plot and target channel from user input\n",
    "select_chan = input(\"Enter the channels to plot (comma-separated or interval): \")\n",
    "target_chan = input(\"Select the target channel: \")\n",
    "\n",
    "def initialize_global_variables():\n",
    "    global channel_suprathreshold_events, real_peaks, channel_thresholds, channel_y_coords, y_ticks, all_absolute_peaks\n",
    "    \n",
    "    # Reset all global variables\n",
    "    channel_suprathreshold_events = {}\n",
    "    channel_thresholds = {}\n",
    "    channel_y_coords = {}\n",
    "    y_ticks = []\n",
    "    real_peaks = []\n",
    "    all_absolute_peaks = {}\n",
    "    window_duration = 10\n",
    "\n",
    "# Call this right after defining it\n",
    "initialize_global_variables()\n",
    "\n",
    "def reset_detection_variables():\n",
    "    global channel_suprathreshold_events, real_peaks\n",
    "    channel_suprathreshold_events.clear()\n",
    "    real_peaks.clear()\n",
    "\n",
    "def exclude_noisy_intervals(peaks, fs_resampled):\n",
    "    excluded_peaks = []\n",
    "    for peak in peaks:\n",
    "        peak_time = peak / fs_resampled\n",
    "        if not any(start <= peak_time <= end for start, end in noisy_intervals):\n",
    "            excluded_peaks.append(peak)\n",
    "    return excluded_peaks\n",
    "\n",
    "def save_ev2_files(_):\n",
    "    global channel_suprathreshold_events\n",
    "    \n",
    "    for channel, events in channel_suprathreshold_events.items():\n",
    "        spa_info = []\n",
    "        \n",
    "        unique_events = sorted(set(events))\n",
    "        \n",
    "        # Convert event times to sample indices\n",
    "        event_samples = [int(event * fs_resampled * 10) for event in unique_events]\n",
    "        \n",
    "        # Exclude events in noisy intervals\n",
    "        event_samples = exclude_noisy_intervals(event_samples, fs_resampled)\n",
    "        \n",
    "        for sample_time in event_samples:\n",
    "            spa_info.append([channel, 0, 0, 0, 0, sample_time])\n",
    "        \n",
    "        spa_info.sort(key=lambda x: x[5])\n",
    "        \n",
    "        output_file = os.path.join(cleaned_path[:-4] + f'_channel_{channel}_spa_peaks.ev2')\n",
    "        \n",
    "        with open(output_file, 'w') as f:\n",
    "            f.write(\"Channel Zeros1 Zeros2 Zeros3 Zeros4 SampleTime\\n\")\n",
    "            for info in spa_info:\n",
    "                f.write(f\"{info[0]} {info[1]} {info[2]} {info[3]} {info[4]} {info[5]}\\n\")\n",
    "        \n",
    "        print(f\"Saved {len(spa_info)} peaks for channel {channel} to {output_file}\")\n",
    "\n",
    "def on_export_button_click(b):\n",
    "    export_to_csv(\"suprathreshold_events.csv\")\n",
    "\n",
    "def visualize_eeg_data(channels_to_plot_str, target_channel, window_duration_str, apply_hamming=False, apply_double_hamming=False, apply_bandpass=False, lowcut=1, highcut=30, scale_amplitude=1.0):\n",
    "    global channel_thresholds, real_peaks, all_absolute_peaks, channel_suprathreshold_events, window_duration\n",
    "\n",
    "    if not hasattr(visualize_eeg_data, 'has_run'):\n",
    "        reset_detection_variables()\n",
    "        visualize_eeg_data.has_run = True\n",
    "\n",
    "    filtered_target_peaks = []\n",
    "\n",
    "    plt.clf()\n",
    "    \n",
    "    # Update window duration based on textbox input\n",
    "    window_duration = float(window_duration_str) if window_duration_str.strip() else 10\n",
    "    window_start = int(start_time * fs_resampled)\n",
    "    window_end = window_start + int(window_duration * fs_resampled)\n",
    "\n",
    "    # Ensure the window end does not exceed the length of the data\n",
    "    data_length = resampled_data.shape[1]\n",
    "    if window_end > data_length:\n",
    "        window_end = data_length\n",
    "\n",
    "    channels_to_plot = []\n",
    "    if channels_to_plot_str.strip():\n",
    "        for part in channels_to_plot_str.split(\",\"):\n",
    "            part = part.strip()\n",
    "            if \"-\" in part:\n",
    "                start, end = map(int, part.split(\"-\"))\n",
    "                channels_to_plot.extend(range(start, end + 1))\n",
    "            else:\n",
    "                channels_to_plot.append(int(part))\n",
    "\n",
    "    num_visible_channels = len(channels_to_plot)\n",
    "\n",
    "    if num_visible_channels > 0:\n",
    "        try:\n",
    "            lowcut = float(lowcut) if lowcut not in [None, ''] else None\n",
    "            highcut = float(highcut) if highcut not in [None, ''] else None\n",
    "        except ValueError:\n",
    "            print(\"Invalid input for lowcut or highcut. Please enter valid numerical values.\")\n",
    "            return\n",
    "\n",
    "        nyquist_freq = fs_resampled / 2\n",
    "        if highcut is not None and highcut > nyquist_freq:\n",
    "            print(f\"Highcut frequency {highcut} exceeds Nyquist frequency {nyquist_freq}.\")\n",
    "            data_to_visualize = resampled_data_high[np.array(channels_to_plot) - 1, window_start:window_end] * scale_amplitude\n",
    "        else:\n",
    "            data_to_visualize = resampled_data[np.array(channels_to_plot) - 1, window_start:window_end] * scale_amplitude\n",
    "\n",
    "        if apply_hamming or apply_double_hamming:\n",
    "            data_to_visualize = apply_hamming_filter(data_to_visualize, fs_resampled, double=apply_double_hamming)\n",
    "\n",
    "        if apply_bandpass:\n",
    "            try:\n",
    "                if lowcut is not None or highcut is not None:\n",
    "                    data_to_visualize = butter_bandpass_filter(data_to_visualize, lowcut, highcut, fs_resampled)\n",
    "            except ValueError:\n",
    "                print(\"Switching from 2 kHz downsampled data to 5 kHz.\")\n",
    "\n",
    "        all_peaks = {}\n",
    "        window_peaks = []\n",
    "        span = 5000\n",
    "\n",
    "        for i, channel_data in enumerate(data_to_visualize):\n",
    "            time = np.linspace(window_start / fs_resampled, window_end / fs_resampled, len(channel_data))\n",
    "            original_channel_number = channels_to_plot[i]\n",
    "\n",
    "            color = 'orange' if original_channel_number == target_channel else '#0f4c5c'\n",
    "            plt.plot(\n",
    "                time - start_time,\n",
    "                channel_data + (num_visible_channels - 1 - i) * span,\n",
    "                color=color,\n",
    "                alpha=0.9,\n",
    "                linewidth=0.5\n",
    "            )\n",
    "\n",
    "            threshold = channel_thresholds.get(original_channel_number, None)\n",
    "            if threshold is not None:\n",
    "                threshold_array = [threshold] * len(channel_data)\n",
    "                peaks = detect_single_event_peaks(channel_data, threshold_array)\n",
    "                averaged_peaks = average_peaks(peaks)\n",
    "                \n",
    "                all_peaks[original_channel_number] = [peak + window_start for peak in averaged_peaks]\n",
    "                \n",
    "                if original_channel_number not in channel_suprathreshold_events:\n",
    "                    channel_suprathreshold_events[original_channel_number] = []\n",
    "\n",
    "                absolute_peaks = [peak + window_start for peak in averaged_peaks]\n",
    "                filtered_peaks = exclude_noisy_intervals(absolute_peaks, fs_resampled)\n",
    "                new_events = [peak / fs_resampled for peak in filtered_peaks]\n",
    "                channel_suprathreshold_events[original_channel_number] = list(set(\n",
    "                    channel_suprathreshold_events[original_channel_number] + new_events\n",
    "                ))\n",
    "\n",
    "                absolute_peaks = [peak + window_start for peak in averaged_peaks]\n",
    "                if original_channel_number == int(target_channel):\n",
    "                    # Filter close peaks by amplitude\n",
    "                    filtered_peaks = filter_peaks_by_amplitude(filtered_peaks, resampled_data[original_channel_number-1])\n",
    "                    for peak in filtered_peaks:\n",
    "                        peak_color = 'purple' if original_channel_number == target_channel else 'red'\n",
    "                        plt.scatter(\n",
    "                            (peak) / fs_resampled - start_time,\n",
    "                            channel_data[peak - window_start] + (num_visible_channels - 1 - i) * span,\n",
    "                            color=peak_color,\n",
    "                            alpha=0.5,\n",
    "                            s=50\n",
    "                        )\n",
    "                        for peak in filtered_peaks:\n",
    "                            if not is_peak_already_annotated(peak, real_peaks, fs_resampled):\n",
    "                                real_peaks.append(peak)\n",
    "\n",
    "        plt.ylim(-span, num_visible_channels * span)\n",
    "        plt.yticks(np.arange(0, num_visible_channels) * span, reversed(channels_to_plot))\n",
    "    else:\n",
    "        plt.ylim(0, 1)\n",
    "\n",
    "    real_peaks = sorted(set(real_peaks))\n",
    "    \n",
    "\n",
    "    plt.xticks(np.linspace(0, window_duration, 11), np.round(np.linspace(start_time, start_time + window_duration, 11), 2))\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Channel')\n",
    "    plt.grid(True, axis='x', linestyle='--', color='gray', alpha=0.5)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    yticks_positions, _ = plt.yticks()\n",
    "    y_ticks.clear()\n",
    "    y_ticks.extend(yticks_positions)\n",
    "    plt.gca().yaxis.set_ticks_position('both')\n",
    "    plt.tick_params(axis='y', labelleft=True, labelright=True)\n",
    "    plt.subplots_adjust(left=0.05, right=0.95)\n",
    "\n",
    "    redraw_threshold_lines()\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "def is_peak_already_annotated(new_peak, real_peaks, fs_resampled, min_distance_ms=100):\n",
    "    min_distance_samples = int(min_distance_ms * fs_resampled / 1000)\n",
    "    for peak in real_peaks:\n",
    "        if abs(peak - new_peak) <= min_distance_samples:\n",
    "            return True\n",
    "    return False\n",
    "    \n",
    "def detect_suprathreshold_peaks_for_target_channel():\n",
    "    global resampled_data, fs_resampled, target_chan, real_peaks, channel_thresholds, channel_suprathreshold_events\n",
    "    \n",
    "    target_channel_data = resampled_data[int(target_chan) - 1]\n",
    "    threshold = channel_thresholds.get(int(target_chan), None)\n",
    "    \n",
    "    if threshold is not None:\n",
    "        threshold_array = [threshold] * len(target_channel_data)\n",
    "        peaks = detect_single_event_peaks(target_channel_data, threshold_array)\n",
    "        averaged_peaks = average_peaks(peaks)\n",
    "        filtered_peaks = exclude_noisy_intervals(averaged_peaks, fs_resampled)\n",
    "        \n",
    "        channel_suprathreshold_events[int(target_chan)] = [(peak / fs_resampled) for peak in filtered_peaks]\n",
    "\n",
    "def update_thresholds():\n",
    "    global channel_thresholds, real_peaks, channel_suprathreshold_events\n",
    "\n",
    "    # Update peaks for entire recording\n",
    "    define_consensus_target_peaks()\n",
    "\n",
    "    # Update suprathreshold events\n",
    "    channel_suprathreshold_events.clear()\n",
    "    for channel, threshold in channel_thresholds.items():\n",
    "        channel_data = resampled_data[channel - 1]\n",
    "        threshold_array = [threshold] * len(channel_data)\n",
    "        peaks = detect_single_event_peaks(channel_data, threshold_array)\n",
    "        averaged_peaks = average_peaks(peaks)\n",
    "        filtered_peaks = exclude_noisy_intervals(averaged_peaks, fs_resampled)\n",
    "        # Convert filtered peaks to time points\n",
    "        channel_suprathreshold_events[channel] = [(peak / fs_resampled) for peak in filtered_peaks]\n",
    "\n",
    "def average_peaks(peaks):\n",
    "    averaged_peaks = []\n",
    "    current_peak_group = []\n",
    "\n",
    "    for peak in peaks:\n",
    "        if current_peak_group and (peak - current_peak_group[-1] < int(0.1 * fs_resampled)):\n",
    "            current_peak_group.append(peak)\n",
    "        else:\n",
    "            if current_peak_group:\n",
    "                averaged_peak = int(np.mean(current_peak_group))\n",
    "                averaged_peaks.append(averaged_peak)\n",
    "            current_peak_group = [peak]\n",
    "\n",
    "    if current_peak_group:\n",
    "        averaged_peak = int(np.mean(current_peak_group))\n",
    "        averaged_peaks.append(averaged_peak)\n",
    "\n",
    "    return averaged_peaks\n",
    "\n",
    "def compute_consensus_peaks(all_peaks):\n",
    "    peak_events = []\n",
    "    for channel, peaks in all_peaks.items():\n",
    "        for peak in peaks:\n",
    "            peak_events.append((peak, channel))\n",
    "    peak_events.sort()\n",
    "\n",
    "    consensus_groups = []\n",
    "    current_group = []\n",
    "\n",
    "    for i, (peak, channel) in enumerate(peak_events):\n",
    "        if not current_group:\n",
    "            current_group = [(peak, channel)]\n",
    "        else:\n",
    "            if abs(peak - current_group[0][0]) <= 0.05 * fs_resampled:\n",
    "                current_group.append((peak, channel))\n",
    "            else:\n",
    "                if len(set(ch for _, ch in current_group)) >= 2:\n",
    "                    consensus_groups.append(current_group)\n",
    "                current_group = [(peak, channel)]\n",
    "    if len(set(ch for _, ch in current_group)) >= 2:\n",
    "        consensus_groups.append(current_group)\n",
    "    \n",
    "    consensus_peaks = []\n",
    "    for group in consensus_groups:\n",
    "        non_target_channels = set(ch for _, ch in group if ch != int(target_chan))\n",
    "        if len(non_target_channels) >= 2:\n",
    "            avg_timestamp = np.mean([peak for peak, _ in group])\n",
    "            consensus_peaks.append(avg_timestamp)\n",
    "    \n",
    "    return consensus_peaks\n",
    "    \n",
    "def get_all_absolute_peaks():\n",
    "    return all_absolute_peaks\n",
    "\n",
    "# Define a function to redraw the threshold lines every time the plot is updated\n",
    "def redraw_threshold_lines():\n",
    "    global channel_thresholds\n",
    "    \n",
    "    for channel, threshold in channel_y_coords.items():\n",
    "        plt.axhline(y=threshold, linestyle='--', color='green', alpha=0.5)\n",
    "\n",
    "def detect_single_event_peaks(channel_data, threshold, min_distance_ms=100):\n",
    "    \"\"\"\n",
    "    Detect peaks in the channel data based on threshold and exclude noisy intervals.\n",
    "    \"\"\"\n",
    "    peaks = []\n",
    "    in_event = False\n",
    "    max_peak_index = None\n",
    "    max_peak_value = -np.inf\n",
    "    min_distance_samples = int(min_distance_ms * fs_resampled / 1000)  # Convert ms to samples\n",
    "\n",
    "    for i, value in enumerate(channel_data):\n",
    "        if (threshold[i] > 0 and value > threshold[i]) or (threshold[i] < 0 and value < threshold[i]):\n",
    "            if not in_event:\n",
    "                in_event = True\n",
    "                max_peak_index = i\n",
    "                max_peak_value = value\n",
    "            else:\n",
    "                if abs(value) > abs(max_peak_value):\n",
    "                    max_peak_value = value\n",
    "                    max_peak_index = i\n",
    "        else:\n",
    "            if in_event:\n",
    "                if max_peak_index is not None:\n",
    "                    peaks.append(max_peak_index)\n",
    "                in_event = False\n",
    "\n",
    "    if peaks:\n",
    "        filtered_peaks = [peaks[0]]\n",
    "        for i in range(1, len(peaks)):\n",
    "            if peaks[i] - peaks[i-1] > min_distance_samples:\n",
    "                filtered_peaks.append(peaks[i])\n",
    "            elif abs(channel_data[peaks[i]]) > abs(channel_data[filtered_peaks[-1]]):\n",
    "                filtered_peaks[-1] = peaks[i]\n",
    "        \n",
    "        # Exclude peaks within noisy intervals\n",
    "        return exclude_noisy_intervals(filtered_peaks, fs_resampled)\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "all_peaks = []\n",
    "timeframe = []\n",
    "\n",
    "def filter_peaks_by_amplitude(peaks, target_data, window_ms=100):\n",
    "    if not peaks:\n",
    "        return []\n",
    "    \n",
    "    sorted_peaks = sorted(peaks)\n",
    "    filtered_peaks = []\n",
    "    current_group = [sorted_peaks[0]]\n",
    "    window_samples = int(window_ms * fs_resampled / 1000)  # Convert ms to samples\n",
    "    \n",
    "    for peak in sorted_peaks[1:]:\n",
    "        if peak - current_group[0] <= window_samples:\n",
    "            current_group.append(peak)\n",
    "        else:\n",
    "            best_peak = max(current_group, key=lambda x: abs(target_data[x]))\n",
    "            filtered_peaks.append(best_peak)\n",
    "            current_group = [peak]\n",
    "    \n",
    "    if current_group:\n",
    "        best_peak = max(current_group, key=lambda x: abs(target_data[x]))\n",
    "        filtered_peaks.append(best_peak)\n",
    "    \n",
    "    return filtered_peaks\n",
    "\n",
    "def update_interactive_components():\n",
    "    interact(visualize_eeg_data,\n",
    "             channels_to_plot_str=channels_to_plot_text,\n",
    "             target_channel=target_channel_text,\n",
    "             window_duration_str=window_duration_text,\n",
    "             threshold_str=threshold_text,\n",
    "             apply_hamming=apply_hamming_checkbox,\n",
    "             apply_double_hamming=apply_double_hamming_checkbox,\n",
    "             apply_bandpass=apply_bandpass_checkbox,\n",
    "             lowcut=lowcut_text,\n",
    "             highcut=highcut_text,\n",
    "             scale_amplitude=fixed(scale_amplitude),\n",
    "             peak_mode=peak_mode_dropdown)\n",
    "\n",
    "scale_amplitude = 1.0\n",
    "\n",
    "def on_key(event):\n",
    "    global start_time, scale_amplitude\n",
    "    if event.key == 'left':\n",
    "        start_time -= window_duration if scroll_fast_checkbox.value else round(window_duration * 0.2, 2)\n",
    "        start_time = max(0, start_time)\n",
    "    elif event.key == 'right':\n",
    "        start_time += window_duration if scroll_fast_checkbox.value else round(window_duration * 0.2, 2)\n",
    "        start_time = min(t - window_duration, start_time)\n",
    "    elif event.key == 'up':\n",
    "        scale_amplitude *= 1.5\n",
    "    elif event.key == 'down':\n",
    "        scale_amplitude /= 1.5\n",
    "\n",
    "    # Ensure window_duration_text.value is passed as a string\n",
    "    window_duration_str = window_duration_text.value if isinstance(window_duration_text.value, str) else str(window_duration_text.value)\n",
    "\n",
    "    visualize_eeg_data(\n",
    "        channels_to_plot_text.value,  # Pass channels_to_plot_str\n",
    "        int(target_channel_text.value),  # Pass target_channel\n",
    "        window_duration_str,  # Pass window_duration_str\n",
    "        apply_hamming=apply_hamming_checkbox.value,\n",
    "        apply_double_hamming=apply_double_hamming_checkbox.value,\n",
    "        apply_bandpass=apply_bandpass_checkbox.value,\n",
    "        lowcut=lowcut_text.value or None,\n",
    "        highcut=highcut_text.value or None,\n",
    "        scale_amplitude=scale_amplitude\n",
    "    )\n",
    "    \n",
    "    redraw_threshold_lines()\n",
    "    plt.draw()\n",
    "\n",
    "channel_y_coords = {}\n",
    "\n",
    "def onclick(event):\n",
    "    global channel_y_coords, channel_thresholds\n",
    "\n",
    "    if event.inaxes is not None:\n",
    "        y_coord = event.ydata\n",
    "        channels_to_plot_str = select_chan.strip()\n",
    "        \n",
    "        channels_to_plot = []\n",
    "        if channels_to_plot_str:\n",
    "            for part in channels_to_plot_str.split(\",\"):\n",
    "                part = part.strip()\n",
    "                if \"-\" in part:\n",
    "                    start, end = map(int, part.split(\"-\"))\n",
    "                    channels_to_plot.extend(range(start, end + 1))\n",
    "                else:\n",
    "                    channels_to_plot.append(int(part))\n",
    "\n",
    "        reversed_y_ticks = y_ticks[::-1]\n",
    "\n",
    "        distances = {channel: abs(reversed_y_ticks[channel_index] - y_coord) \n",
    "                    for channel_index, channel in enumerate(channels_to_plot)}\n",
    "        closest_channels = sorted(distances, key=distances.get)[:2]\n",
    "\n",
    "        peak_mode = peak_mode_dropdown.value\n",
    "        if peak_mode == 'Positive':\n",
    "            # Select the channel with the higher index\n",
    "            closest_channel = max(closest_channels)\n",
    "        elif peak_mode == 'Negative':\n",
    "            # Select the channel with the lower index\n",
    "            closest_channel = min(closest_channels)\n",
    "\n",
    "        closest_channel_index = channels_to_plot.index(closest_channel)\n",
    "\n",
    "        if event.button == 1:  # Left click to add/update threshold\n",
    "            channel_y_coords[closest_channel] = y_coord\n",
    "            channel_thresholds[closest_channel] = y_coord - reversed_y_ticks[closest_channel_index]\n",
    "            print(\"New threshold value for Channel\", closest_channel, \":\", channel_thresholds[closest_channel])\n",
    "        elif event.button == 3:  # Right click to delete threshold\n",
    "            if closest_channel in channel_y_coords:\n",
    "                del channel_y_coords[closest_channel]\n",
    "            if closest_channel in channel_thresholds:\n",
    "                del channel_thresholds[closest_channel]\n",
    "            print(\"Threshold value for Channel\", closest_channel, \"deleted\")\n",
    "\n",
    "        detect_suprathreshold_peaks_for_target_channel()\n",
    "\n",
    "        visualize_eeg_data(channels_to_plot_text.value,\n",
    "                          int(target_channel_text.value),\n",
    "                          window_duration_text.value,\n",
    "                          apply_hamming=apply_hamming_checkbox.value,\n",
    "                          apply_double_hamming=apply_double_hamming_checkbox.value,\n",
    "                          apply_bandpass=apply_bandpass_checkbox.value,\n",
    "                          lowcut=lowcut_text.value or None,\n",
    "                          highcut=highcut_text.value or None,\n",
    "                          scale_amplitude=scale_amplitude)\n",
    "        \n",
    "        redraw_threshold_lines()\n",
    "        \n",
    "        if closest_channel == int(target_channel_text.value):\n",
    "            plt.axhline(y=y_coord, linestyle='--', color='green')\n",
    "        \n",
    "        plt.draw()\n",
    "\n",
    "export_ev2_button = widgets.Button(description=\"Export to EV2\")\n",
    "export_ev2_button.on_click(save_ev2_files)\n",
    "display(export_ev2_button)\n",
    "\n",
    "# Define interactive components\n",
    "window_duration_text = widgets.Text(value='10', description='Window Duration')\n",
    "channels_to_plot_text = widgets.Text(value=select_chan, description='Channels to Plot')\n",
    "target_channel_text = widgets.Text(value=target_chan, description='Target Channel')\n",
    "apply_hamming_checkbox = widgets.Checkbox(value=True, description='Apply Hamming')\n",
    "apply_double_hamming_checkbox = widgets.Checkbox(value=False, description='Apply Double Hamming')\n",
    "apply_bandpass_checkbox = widgets.Checkbox(value=True, description='Apply Bandpass')\n",
    "lowcut_text = widgets.Text(value='1', placeholder='Lowcut (Hz)', description='Lowcut:')\n",
    "highcut_text = widgets.Text(value='30', placeholder='Highcut (Hz)', description='Highcut:')\n",
    "\n",
    "# Global variable to store thresholds for each channel\n",
    "thresholds = {}\n",
    "\n",
    "interact(visualize_eeg_data,\n",
    "         channels_to_plot_str=channels_to_plot_text,\n",
    "         target_channel=target_channel_text,\n",
    "         window_duration_str=window_duration_text,\n",
    "         apply_hamming=apply_hamming_checkbox,\n",
    "         apply_double_hamming=apply_double_hamming_checkbox,\n",
    "         apply_bandpass=apply_bandpass_checkbox,\n",
    "         lowcut=lowcut_text or None,\n",
    "         highcut=highcut_text or None,\n",
    "         scale_amplitude=fixed(scale_amplitude),\n",
    "         **thresholds)\n",
    "\n",
    "scroll_fast_checkbox = widgets.Checkbox(\n",
    "    value=False,  # Unchecked by default\n",
    "    description='Fast Scroll',\n",
    "    disabled=False,\n",
    "    indent=False\n",
    ")\n",
    "\n",
    "peak_mode_dropdown = widgets.Dropdown(\n",
    "    options=['Positive', 'Negative'],\n",
    "    value='Positive',\n",
    "    description='Peak Mode'\n",
    ")\n",
    "\n",
    "plt.gcf().canvas.mpl_connect('key_press_event', on_key)\n",
    "plt.gcf().canvas.mpl_connect('button_press_event', onclick)  # Connect onclick event\n",
    "scale_amplitude = 1.0\n",
    "lowcut_text.observe(on_lowcut_change, names='value')\n",
    "highcut_text.observe(on_highcut_change, names='value')\n",
    "\n",
    "snapshot_button = widgets.Button(description='Take a Snapshot', button_style='info')\n",
    "snapshot_button.on_click(save_snapshot)\n",
    "display(peak_mode_dropdown)\n",
    "display(snapshot_button)\n",
    "display(scroll_fast_checkbox)\n",
    "\n",
    "reset_button = widgets.Button(description=\"Reset Detection\")\n",
    "reset_button.on_click(lambda b: reset_detection_variables())\n",
    "display(reset_button) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1293e89d-1f55-4fe4-9add-f0ace25ae06c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94c0317d86104ff6972a8f680d238806",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='6', description='Target Channel:', placeholder='Target Channel')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7791617ec34141018ef02faeac550f90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='File Path:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54c4fd5cee4f44f0b74607d0eb0b7b98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='success', description='Import .ev2 file', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e16a2c82eef4a6991f878cd2fb655a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Remove Duplicates', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b447e09c486c46efaa9e1a3e595952e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='info', description='Save .ev2 file', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0246179237ec4fd1822492aff62f526d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Text(value='10', description='Window Duration'), Text(value='', description='Hidden Chan…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d04a9df00a644c2b76387ea944b25b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Peak Mode', options=('Positive', 'Negative'), value='Positive')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59c4792a7e1e4984954882d26d13de2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='info', description='Take a Snapshot', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4ee2500ac75408eb7e2d180b50e9667",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Checkbox(value=False, description='Scroll Fast', indent=False)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "try:\n",
    "    real_peaks\n",
    "except NameError:\n",
    "    real_peaks = []\n",
    "\n",
    "# Initialize global variables\n",
    "start_time = 0\n",
    "scale_amplitude = 10.0\n",
    "\n",
    "def read_ev2_file(file_path):\n",
    "    events = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file.readlines()[1:]:  # Skip the header line\n",
    "            parts = line.split()\n",
    "            if len(parts) == 6:\n",
    "                event_time = int(parts[5]) / 10  # Divide by 10\n",
    "                events.append(event_time)\n",
    "    print(f\"Read {len(events)} events from file.\")\n",
    "    return events\n",
    "\n",
    "def import_ev2_file(_):\n",
    "    global real_peaks\n",
    "\n",
    "    file_path = file_path_text.value.strip(' \"\\'')\n",
    "    file_path = os.path.normpath(file_path)  # Normalize the file path\n",
    "    \n",
    "    if os.path.exists(file_path):\n",
    "        events = read_ev2_file(file_path)\n",
    "        new_peaks = [int(event) for event in events]  # Convert to sample indices\n",
    "        real_peaks = list(set(new_peaks))  # Remove duplicates and sort\n",
    "        real_peaks.sort()\n",
    "\n",
    "        print(f\"Imported {len(events)} events from {file_path}\")\n",
    "        print(f\"Updated real_peaks: {real_peaks}\")\n",
    "\n",
    "        # Re-visualize the EEG data with the new events\n",
    "        visualize_eeg_data(\n",
    "            window_duration_text.value,\n",
    "            hidden_channels_text.value,\n",
    "            apply_hamming_checkbox.value,\n",
    "            apply_double_hamming_checkbox.value,\n",
    "            apply_bandpass_checkbox.value,\n",
    "            lowcut_text.value,\n",
    "            highcut_text.value,\n",
    "            scale_amplitude\n",
    "        )\n",
    "    else:\n",
    "        print(\"File not found. Please check the path and try again.\")\n",
    "\n",
    "def visualize_eeg_data(window_duration_str, hidden_channels_str, apply_hamming=False, apply_double_hamming=False, apply_bandpass=False, lowcut=1, highcut=30, scale_amplitude=10.0):\n",
    "    plt.clf()  \n",
    "\n",
    "    global resamp_data, fs_resampled, num_channels, window_duration, start_time, real_peaks\n",
    "\n",
    "    window_duration = float(window_duration_str)\n",
    "    window_start = int(start_time * fs_resampled)\n",
    "    window_end = window_start + int(window_duration * fs_resampled)\n",
    "\n",
    "    data_length = resamp_data.shape[1]\n",
    "    if window_end > data_length:\n",
    "        window_end = data_length\n",
    "\n",
    "    hidden_channels = []\n",
    "    if hidden_channels_str.strip() and hidden_channels_str != '':\n",
    "        hidden_channels = [int(ch) for ch in hidden_channels_str.split(\",\")]\n",
    "\n",
    "    selected_channels = np.array([channel for channel in range(1, num_channels + 1) if channel not in hidden_channels])\n",
    "\n",
    "    num_visible_channels = len(selected_channels)\n",
    "    span = 5000\n",
    "\n",
    "    if num_visible_channels > 0:\n",
    "        try:\n",
    "            lowcut = float(lowcut) if lowcut not in [None, ''] else None\n",
    "            highcut = float(highcut) if highcut not in [None, ''] else None\n",
    "        except ValueError:\n",
    "            print(\"Invalid input for lowcut or highcut. Please enter valid numerical values.\")\n",
    "            return\n",
    "\n",
    "        nyquist_freq = fs_resampled / 2\n",
    "        if highcut is not None and highcut > nyquist_freq:\n",
    "            print(f\"Highcut frequency {highcut} exceeds Nyquist frequency {nyquist_freq}.\")\n",
    "            data_to_visualize = resamp_data_high[selected_channels - 1, window_start:window_end] * scale_amplitude\n",
    "        else:\n",
    "            data_to_visualize = resamp_data[selected_channels - 1, window_start:window_end] * scale_amplitude\n",
    "\n",
    "        if apply_hamming or apply_double_hamming:\n",
    "            data_to_visualize = apply_hamming_filter(data_to_visualize, fs_resampled, double=apply_double_hamming)\n",
    "\n",
    "        if apply_bandpass:\n",
    "            try:\n",
    "                if lowcut is not None or highcut is not None:\n",
    "                    data_to_visualize = butter_bandpass_filter(data_to_visualize, lowcut, highcut, fs_resampled)\n",
    "            except ValueError:\n",
    "                print(\"Switching from 2 kHz downsampled data to 5 kHz.\")\n",
    "\n",
    "        for i, channel_data in enumerate(data_to_visualize):\n",
    "            time = np.linspace(window_start / fs_resampled, window_end / fs_resampled, len(channel_data))\n",
    "            plt.plot(time - start_time, channel_data + (num_visible_channels - 1 - i) * span, color='#335c67', alpha=0.7, linewidth=0.5)  \n",
    "            \n",
    "            for peak_index in list(real_peaks):\n",
    "                peak_time = peak_index / fs_resampled\n",
    "                if peak_time >= start_time and peak_time < start_time + window_duration:\n",
    "                    peak_start = max(peak_time - 0.150, start_time)\n",
    "                    peak_end = min(peak_time + 0.150, start_time + window_duration)\n",
    "                    plt.axvspan(peak_start - start_time, peak_end - start_time, color='#540b0e', alpha=0.01)\n",
    "                    plt.axvline(peak_time - start_time, color='k', linestyle='--', linewidth=0.5, alpha=0.3)\n",
    "\n",
    "        plt.ylim(-span, num_visible_channels * span)  \n",
    "        plt.yticks(np.arange(0, num_visible_channels) * span, reversed(selected_channels))  \n",
    "    else:\n",
    "        plt.ylim(0, 1)  \n",
    "\n",
    "    plt.xticks(np.linspace(0, window_duration, 11), np.round(np.linspace(start_time, start_time + window_duration, 11), 2))  \n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Channel')\n",
    "    plt.grid(True, axis='x', linestyle='--', color='#e09f3e', alpha=0.5)\n",
    "    plt.tight_layout()\n",
    "    plt.gca().yaxis.set_ticks_position('both')\n",
    "    plt.tick_params(axis='y', labelleft=True, labelright=True)\n",
    "    plt.subplots_adjust(left=0.05, right=0.95)\n",
    "    plt.show()\n",
    "\n",
    "snapshot_counter = 1\n",
    "    \n",
    "def save_snapshot(_):\n",
    "    global snapshot_counter\n",
    "    snap_path = os.path.join(cleaned_path[:-4] + f'_overall_window{snapshot_counter}.svg')\n",
    "    snapshot_counter += 1\n",
    "    plt.savefig(snap_path, bbox_inches='tight')\n",
    "\n",
    "def on_key(event):\n",
    "    global start_time\n",
    "    if event.key == 'left':\n",
    "        start_time -= window_duration if scroll_fast_checkbox.value else round(window_duration * 0.2, 2)\n",
    "        start_time = max(0, start_time)\n",
    "    elif event.key == 'right':\n",
    "        start_time += window_duration if scroll_fast_checkbox.value else round(window_duration * 0.2, 2)\n",
    "        start_time = min(t - window_duration, start_time)\n",
    "\n",
    "    # Ensure window_duration_text.value is passed as a string\n",
    "    window_duration_str = window_duration_text.value if isinstance(window_duration_text.value, str) else str(window_duration_text.value)\n",
    "\n",
    "    visualize_eeg_data(channels_to_plot_text.value,\n",
    "                       int(target_channel_text.value),\n",
    "                       window_duration_str,\n",
    "                       apply_hamming=apply_hamming_checkbox.value, \n",
    "                       apply_double_hamming=apply_double_hamming_checkbox.value,\n",
    "                       apply_bandpass=apply_bandpass_checkbox.value,\n",
    "                       lowcut=lowcut_text.value or None,\n",
    "                       highcut=highcut_text.value or None,\n",
    "                       scale_amplitude=scale_amplitude)\n",
    "\n",
    "    plt.draw()\n",
    "\n",
    "window_duration_text = widgets.Text(value='10', description='Window Duration')\n",
    "hidden_channels_text = widgets.Text(value='', description='Hidden Channels')\n",
    "apply_hamming_checkbox = widgets.Checkbox(value=True, description='Apply Hamming')\n",
    "apply_double_hamming_checkbox = widgets.Checkbox(value=False, description='Apply Double Hamming')\n",
    "apply_bandpass_checkbox = widgets.Checkbox(value=True, description='Apply Bandpass')\n",
    "lowcut_text = widgets.Text(value='1', placeholder='Lowcut (Hz)', description='Lowcut:')\n",
    "highcut_text = widgets.Text(value='30', placeholder='Highcut (Hz)', description='Highcut:')\n",
    "\n",
    "plt.gcf().canvas.mpl_connect('key_press_event', on_key)\n",
    "\n",
    "scale_amplitude = 10.0\n",
    "\n",
    "def on_arrow_key(event):\n",
    "    global scale_amplitude\n",
    "    if event.key == 'up':\n",
    "        scale_amplitude *= 1.5\n",
    "    elif event.key == 'down':\n",
    "        scale_amplitude /= 1.5\n",
    "    visualize_eeg_data(\n",
    "        window_duration_text.value,\n",
    "        hidden_channels_text.value,\n",
    "        apply_hamming_checkbox.value,\n",
    "        apply_double_hamming_checkbox.value,\n",
    "        apply_bandpass_checkbox.value,\n",
    "        lowcut_text.value,\n",
    "        highcut_text.value,\n",
    "        scale_amplitude\n",
    "    )\n",
    "    plt.draw()\n",
    "\n",
    "plt.gcf().canvas.mpl_connect('key_press_event', on_arrow_key)\n",
    "\n",
    "def remove_duplicates():\n",
    "    global real_peaks\n",
    "    real_peaks = list(set(real_peaks))\n",
    "\n",
    "def save_ev2_file(_):\n",
    "    global real_peaks, spike_item_number\n",
    "    spa_info = []\n",
    "    item_number = 1\n",
    "    recalc_peaks = [peak * 10 for peak in real_peaks]\n",
    "    for spa_time in recalc_peaks:\n",
    "        spa_info.append([item_number, 0, 0, 0, 0, spa_time])\n",
    "        item_number += 1\n",
    "\n",
    "    output_file = os.path.join(cleaned_path[:-4] + '_spa_peaks.ev2')\n",
    "\n",
    "    with open(output_file, 'w') as f:\n",
    "        f.write(\"SPA Type Zeros1 Zeros2 Zeros3 SampleTime\\n\")\n",
    "        for info in spa_info:\n",
    "            f.write(f\"{info[0]} {info[1]} {info[2]} {info[3]} {info[4]} {info[5]}\\n\")\n",
    "\n",
    "def on_click(event):\n",
    "    global start_time, real_peaks, resamp_data, fs_resampled, target_chan_text\n",
    "\n",
    "    if event.button == 3:  # Right-click to remove a peak\n",
    "        click_time = event.xdata + start_time\n",
    "        for i, peak_index in enumerate(real_peaks):\n",
    "            peak_time = peak_index / fs_resampled\n",
    "            if abs(click_time - peak_time) < 0.150:\n",
    "                del real_peaks[i]\n",
    "                break\n",
    "        visualize_eeg_data(\n",
    "            window_duration_text.value,\n",
    "            hidden_channels_text.value,\n",
    "            apply_hamming_checkbox.value,\n",
    "            apply_double_hamming_checkbox.value,\n",
    "            apply_bandpass_checkbox.value,\n",
    "            lowcut_text.value,\n",
    "            highcut_text.value,\n",
    "            scale_amplitude\n",
    "        )\n",
    "        plt.draw()\n",
    "    elif event.button == 1:  # Left-click to add a peak\n",
    "        click_time = event.xdata + start_time\n",
    "        click_sample = int(click_time * fs_resampled)\n",
    "    \n",
    "        try:\n",
    "            target_channel = int(target_chan_text.value)\n",
    "        except ValueError:\n",
    "            return\n",
    "    \n",
    "        window_start = max(click_sample - int(0.150 * fs_resampled), 0)\n",
    "        window_end = min(click_sample + int(0.150 * fs_resampled), resamp_data.shape[1] - 1)\n",
    "        window_data = resamp_data[target_channel - 1, window_start:window_end]\n",
    "    \n",
    "        if peak_mode_dropdown.value == 'Positive':\n",
    "            peak_index_within_window = np.argmax(window_data)\n",
    "        elif peak_mode_dropdown.value == 'Negative':\n",
    "            peak_index_within_window = np.argmin(window_data)\n",
    "        else:\n",
    "            peak_index_within_window = np.argmax(np.abs(window_data))\n",
    "    \n",
    "        absolute_peak_index_within_window = window_start + peak_index_within_window\n",
    "        real_peaks.append(absolute_peak_index_within_window)\n",
    "        real_peaks = list(set(real_peaks))\n",
    "        real_peaks.sort()\n",
    "\n",
    "        visualize_eeg_data(\n",
    "            window_duration_text.value,\n",
    "            hidden_channels_text.value,\n",
    "            apply_hamming_checkbox.value,\n",
    "            apply_double_hamming_checkbox.value,\n",
    "            apply_bandpass_checkbox.value,\n",
    "            lowcut_text.value,\n",
    "            highcut_text.value,\n",
    "            scale_amplitude\n",
    "        )\n",
    "        plt.draw()\n",
    "\n",
    "remove_duplicates_button = widgets.Button(description='Remove Duplicates')\n",
    "remove_duplicates_button.on_click(remove_duplicates)\n",
    "\n",
    "# Widgets\n",
    "target_chan_text = widgets.Text(value=target_chan if 'target_chan' in globals() else '', placeholder='Target Channel', description='Target Channel:')\n",
    "display(target_chan_text)\n",
    "\n",
    "save_ev2_button = widgets.Button(description='Save .ev2 file', button_style='info')\n",
    "save_ev2_button.on_click(save_ev2_file)\n",
    "\n",
    "file_path_text = widgets.Text(value='', description='File Path:')\n",
    "import_ev2_button = widgets.Button(description='Import .ev2 file', button_style='success')\n",
    "import_ev2_button.on_click(import_ev2_file)\n",
    "\n",
    "display(file_path_text)\n",
    "display(import_ev2_button)\n",
    "display(remove_duplicates_button)\n",
    "display(save_ev2_button)\n",
    "lowcut_text.observe(on_lowcut_change, names='value')\n",
    "highcut_text.observe(on_highcut_change, names='value')\n",
    "plt.gcf().canvas.mpl_connect('button_press_event', on_click)\n",
    "plt.gcf().canvas.mpl_connect('key_press_event', on_key)\n",
    "\n",
    "interact(\n",
    "    visualize_eeg_data,\n",
    "    window_duration_str=window_duration_text,\n",
    "    hidden_channels_str=hidden_channels_text,\n",
    "    apply_hamming=apply_hamming_checkbox,\n",
    "    apply_double_hamming=apply_double_hamming_checkbox,\n",
    "    apply_bandpass=apply_bandpass_checkbox,\n",
    "    lowcut=lowcut_text,\n",
    "    highcut=highcut_text,\n",
    "    scale_amplitude=widgets.FloatSlider(value=scale_amplitude, min=1, max=100, step=1, description='Scale Amplitude')\n",
    ")\n",
    "scroll_fast_checkbox = widgets.Checkbox(\n",
    "    value=False,  # Unchecked by default\n",
    "    description='Scroll Fast',\n",
    "    disabled=False,\n",
    "    indent=False\n",
    ")\n",
    "peak_mode_dropdown = widgets.Dropdown(\n",
    "    options=['Positive', 'Negative'],\n",
    "    value='Positive',\n",
    "    description='Peak Mode'\n",
    ")\n",
    "display(peak_mode_dropdown)\n",
    "\n",
    "snapshot_button = widgets.Button(description='Take a Snapshot', button_style='info')\n",
    "snapshot_button.on_click(save_snapshot)\n",
    "display(snapshot_button)\n",
    "display(scroll_fast_checkbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a82f31a-04ff-4ccf-9a51-45c16c4b4381",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79199d1f8a114062a08518b57f9b4126",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='success', description='Save Plots', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waveforms min/max: -0.2875447633280092 0.06181717994215024\n",
      "Heatmap min/max: -0.2875447633280092 0.2570548262997873\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "926509fdf56a4fabac19fa0d624ad0aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntRangeSlider(value=(1, 23), continuous_update=False, description='Channels', max=23, min=1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6fa08e2afe44a75aca514962378c0d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatRangeSlider(value=(-0.2875447633280092, 0.2875447633280092), continuous_update=False, description='Amplit…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to 'lfp_analysis.csv' and 'lfp_max_min_peaks.csv'.\n",
      "abs_norm_snippets shape: (423, 23, 1200)\n",
      "max_peaks shape: (423, 7)\n",
      "min_peaks shape: (423, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-24 20:35:57.494 python3.13[84592:26391550] The class 'NSSavePanel' overrides the method identifier.  This method is implemented by class 'NSWindow'\n"
     ]
    }
   ],
   "source": [
    "def save_figure(fig, filename):\n",
    "    fig.savefig(filename, format='svg')\n",
    "\n",
    "def plot_heatmap_interactive(corrected_snippets, fs_resampled, save_button):\n",
    "    # Compute the mean of corrected snippets along axis 0 and convert to microvolts\n",
    "    heatmap_data = np.mean(corrected_snippets, axis=0) * INT16_TO_UV\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    ax.set_ylim(heatmap_data.min(), heatmap_data.max())\n",
    "\n",
    "    # Create sliders with 1-based index for channels\n",
    "    channel_slider = widgets.IntRangeSlider(\n",
    "        value=[1, heatmap_data.shape[0]],  # start from 1\n",
    "        min=1,  # starting from 1\n",
    "        max=heatmap_data.shape[0],\n",
    "        step=1,\n",
    "        description=\"Channels\",\n",
    "        continuous_update=False,\n",
    "    )\n",
    "\n",
    "    # Set amplitude slider range symmetric around zero\n",
    "    max_abs_val = max(abs(heatmap_data.min()), abs(heatmap_data.max()))\n",
    "    amplitude_slider = widgets.FloatRangeSlider(\n",
    "        value=[-max_abs_val, max_abs_val],\n",
    "        min=-max_abs_val,\n",
    "        max=max_abs_val,\n",
    "        step=(2 * max_abs_val) / 100,\n",
    "        description=\"Amplitude (μV)\",\n",
    "        continuous_update=False,\n",
    "    )\n",
    "    print(\"Heatmap min/max:\", heatmap_data.min(), heatmap_data.max())\n",
    "\n",
    "    def update_plot(channel_range, amplitude_range):\n",
    "        selected_channels = heatmap_data[channel_range[0]-1:channel_range[1], :]\n",
    "        vmin, vmax = amplitude_range\n",
    "\n",
    "        # Refresh the plot - selected channels fixalas!!\n",
    "        ax.clear()\n",
    "        im = ax.imshow(\n",
    "            selected_channels,\n",
    "            aspect=\"auto\",\n",
    "            cmap=\"jet_r\",  # Use a diverging colormap\n",
    "            extent=[-300, 300, channel_range[1], channel_range[0]],  # Adjust to 1-based indexing\n",
    "            vmin=vmin,\n",
    "            vmax=vmax,\n",
    "        )\n",
    "        ax.set_xlabel(\"Time (ms)\")\n",
    "        ax.set_ylabel(\"Channel\")\n",
    "        ax.set_title(\"LFPg Heatmap\")\n",
    "\n",
    "        # Add colorbar only once\n",
    "        if not hasattr(update_plot, \"colorbar\") or update_plot.colorbar is None:\n",
    "            update_plot.colorbar = fig.colorbar(im, ax=ax, label=\"Amplitude (μV)\")\n",
    "        else:\n",
    "            # Update the color limits for the existing colorbar\n",
    "            im.set_clim(vmin, vmax)\n",
    "            update_plot.colorbar.set_label(\"Amplitude (μV)\")\n",
    "\n",
    "        plt.draw()\n",
    "\n",
    "    # Link sliders to the plotting function\n",
    "    widgets.interactive(\n",
    "        update_plot,\n",
    "        channel_range=channel_slider,\n",
    "        amplitude_range=amplitude_slider,\n",
    "    )\n",
    "\n",
    "    # Display sliders and initial plot\n",
    "    display(channel_slider, amplitude_slider)\n",
    "    update_plot(channel_slider.value, amplitude_slider.value)\n",
    "\n",
    "    # Define save button action\n",
    "    def on_save_button_clicked(b):\n",
    "        save_path = os.path.join(cleaned_path[:-4] + \"_lfpg_heatmap.svg\")\n",
    "        save_figure(fig, save_path)\n",
    "        print(f\"Heatmap saved to {save_path}\")\n",
    "\n",
    "    save_button.on_click(on_save_button_clicked)\n",
    "\n",
    "# Function to plot averaged waveforms\n",
    "def plot_averaged_waveforms(averaged_waveforms, channels_to_plot, fs_resampled, save_button):\n",
    "    time = np.linspace(-0.3, 0.3, averaged_waveforms.shape[1])\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    # Convert waveform to microvolts for plotting\n",
    "    for i, waveform in enumerate(averaged_waveforms):\n",
    "        ax.plot(time, waveform, label=f'Channel {channels_to_plot[i]+1}')  # Correct 1-based index\n",
    "    ax.set_xlabel('Time (s)')\n",
    "    ax.set_ylabel('Amplitude (μV)')\n",
    "    ax.set_title('Averaged LFP Sweep Waveforms')\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "    print(\"Waveforms min/max:\", averaged_waveforms.min(), averaged_waveforms.max())\n",
    "\n",
    "    # Define save button action\n",
    "    def on_save_button_clicked(b):\n",
    "        save_path = os.path.join(cleaned_path[:-4] + \"_lfpg_averaged_waveforms.svg\")\n",
    "        save_figure(fig, save_path)\n",
    "        print(f\"Averaged waveforms saved to {save_path}\")\n",
    "\n",
    "    save_button.on_click(on_save_button_clicked)\n",
    "\n",
    "# Modify process_lfp_data for 1-based indexing and baseline correction\n",
    "def process_lfp_data(resampled_data, fs_resampled, real_peaks, select_chan):\n",
    "    # User input for selected channels (1-based index)\n",
    "    channels_to_plot_str = select_chan.strip()\n",
    "    channels_to_plot = []\n",
    "    if channels_to_plot_str:\n",
    "        for part in channels_to_plot_str.split(\",\"):\n",
    "            part = part.strip()\n",
    "            if \"-\" in part:\n",
    "                start, end = map(int, part.split(\"-\"))\n",
    "                channels_to_plot.extend(range(start-1, end))  # Convert to 0-based index\n",
    "            else:\n",
    "                channels_to_plot.append(int(part) - 1)  # Convert to 0-based index\n",
    "\n",
    "    # Step A: Filter the data\n",
    "    filtered_data = butter_bandpass_filter(resampled_data, 1, 30, fs_resampled)\n",
    "    hamming_filtered_data = apply_hamming_filter(filtered_data, fs_resampled)\n",
    "\n",
    "    # Step B: Extract snippets\n",
    "    snippet_range = int(0.3 * fs_resampled)\n",
    "    snippets = []\n",
    "    for peak in real_peaks:\n",
    "        if peak - snippet_range >= 0 and peak + snippet_range < hamming_filtered_data.shape[1]:\n",
    "            snippets.append(hamming_filtered_data[:, peak - snippet_range:peak + snippet_range])\n",
    "\n",
    "    snippets = np.array(snippets)  # Shape: (num_events, num_channels, snippet_length)\n",
    "\n",
    "    # Baseline correction\n",
    "    baseline_period = int(0.2 * fs_resampled)  # First 200 ms\n",
    "    baselines = snippets[:, :, :baseline_period].mean(axis=2, keepdims=True)\n",
    "    corrected_snippets = snippets - baselines\n",
    "\n",
    "    # Step D: Recurrence frequency\n",
    "    total_noisy_duration = sum(end - start for start, end in noisy_intervals)\n",
    "\n",
    "    # Compute the effective duration of the file after subtracting noisy intervals\n",
    "    total_file_duration = resampled_data.shape[1] / fs_resampled  # Duration of the file in seconds\n",
    "    effective_duration = total_file_duration - total_noisy_duration\n",
    "\n",
    "    # Compute recurrence frequency using the effective duration\n",
    "    recurrence_frequency = len(real_peaks) / effective_duration if effective_duration > 0 else 0\n",
    "\n",
    "    # Step E: LFPg peak analysis (for selected channels)\n",
    "    # Multiply by conversion for microvolt units\n",
    "    max_peaks = np.max(corrected_snippets[:, channels_to_plot, :] * INT16_TO_UV, axis=2)\n",
    "    min_peaks = np.min(corrected_snippets[:, channels_to_plot, :] * INT16_TO_UV, axis=2)\n",
    "\n",
    "    isi_list = []\n",
    "    real_peaks = np.array(real_peaks)\n",
    "    for i in range(1, len(real_peaks)):\n",
    "        prev_peak_time = real_peaks[i-1] / fs_resampled\n",
    "        curr_peak_time = real_peaks[i] / fs_resampled\n",
    "        # Check if any noisy interval overlaps with this ISI\n",
    "        isi_noisy = False\n",
    "        for start, end in noisy_intervals:\n",
    "            # If the noisy interval is strictly between the two peaks (not touching peaks)\n",
    "            if (prev_peak_time < end and curr_peak_time > start):\n",
    "                isi_noisy = True\n",
    "                break\n",
    "        if isi_noisy:\n",
    "            isi_list.append(np.nan)\n",
    "        else:\n",
    "            isi_list.append(curr_peak_time - prev_peak_time)\n",
    "    isi_list = np.array(isi_list)\n",
    "    isi_mean = np.nanmean(isi_list) if np.any(~np.isnan(isi_list)) else np.nan\n",
    "\n",
    "    # Compute averaged waveforms for selected channels (convert to microvolts)\n",
    "    averaged_waveforms = np.mean(corrected_snippets[:, channels_to_plot, :], axis=0) * INT16_TO_UV\n",
    "    # Average amplitudes of max and min peaks for selected channels\n",
    "    avg_max_peaks = np.mean(max_peaks, axis=0)\n",
    "    avg_min_peaks = np.mean(min_peaks, axis=0)\n",
    "\n",
    "    averaged_waveform_peaks = np.max(np.abs(averaged_waveforms), axis=1)\n",
    "    max_channel_idx = channels_to_plot[np.argmax(averaged_waveform_peaks)] + 1\n",
    "    \n",
    "    # Create save button\n",
    "    save_button = widgets.Button(description=\"Save Plots\", button_style='success')\n",
    "    display(save_button)\n",
    "\n",
    "    # Plot averaged waveforms\n",
    "    plot_averaged_waveforms(averaged_waveforms, channels_to_plot, fs_resampled, save_button)\n",
    "\n",
    "    # Step G: Interactive Heatmap\n",
    "    plot_heatmap_interactive(corrected_snippets, fs_resampled, save_button)\n",
    "    \n",
    "    # Step H: Export max and min peaks for selected channels\n",
    "    max_min_peaks_data = {\n",
    "        f\"Channel {channels_to_plot[i]+1} Max Peaks (μV)\": max_peaks[:, i]\n",
    "        for i in range(len(channels_to_plot))\n",
    "    }\n",
    "    max_min_peaks_data.update({\n",
    "        f\"Channel {channels_to_plot[i]+1} Min Peaks (μV)\": min_peaks[:, i]\n",
    "        for i in range(len(channels_to_plot))\n",
    "    })\n",
    "    max_min_peaks_df = pd.DataFrame(max_min_peaks_data)\n",
    "\n",
    "    # Add ISI list as a column to the max_min_peaks DataFrame (still in seconds)\n",
    "    isi_df = pd.DataFrame({\"ISI List (s)\": isi_list})\n",
    "    max_min_peaks_df = pd.concat([max_min_peaks_df, isi_df], axis=1)\n",
    "\n",
    "    max_min_peaks_df.to_csv(os.path.join(cleaned_path[:-4] + \"_lfp_max_min_peaks.csv\"), index=False)\n",
    "\n",
    "    # Save recurrence frequency, average peak values for each channel, and max channel in a separate CSV\n",
    "    results = {\n",
    "        \"Recurrence Frequency (Hz)\": [recurrence_frequency],\n",
    "        \"ISI Mean (s)\": [isi_mean],\n",
    "    }\n",
    "\n",
    "    # Add separate columns for each channel's average max and min peaks\n",
    "    for i, chan in enumerate(channels_to_plot):\n",
    "        results[f\"Avg Max Peak (Channel {chan+1}) (μV)\"] = [avg_max_peaks[i]]  # Convert to 1-based index\n",
    "        results[f\"Avg Min Peak (Channel {chan+1}) (μV)\"] = [avg_min_peaks[i]]  # Convert to 1-based index\n",
    "\n",
    "    # Add the channel with the highest peak\n",
    "    results[\"Channel with Highest Average Peak\"] = [max_channel_idx]  # Keep 1-based index\n",
    "\n",
    "    results_df = pd.DataFrame.from_dict(results, orient=\"index\").T\n",
    "\n",
    "    results_df.to_csv(os.path.join(cleaned_path[:-4] + \"_lfp_analysis.csv\"), index=False)\n",
    "\n",
    "    print(\"Results saved to 'lfp_analysis.csv' and 'lfp_max_min_peaks.csv'.\")\n",
    "    print(\"abs_norm_snippets shape:\", corrected_snippets.shape)\n",
    "    print(\"max_peaks shape:\", max_peaks.shape)\n",
    "    print(\"min_peaks shape:\", min_peaks.shape)\n",
    "\n",
    "# Prompt the user for selected channels only if select_chan is not defined\n",
    "try:\n",
    "    select_chan\n",
    "except NameError:\n",
    "    select_chan = input(\"Please enter the channels for which you need the waveforms (e.g., '1,2,3' or '1-3'): \")\n",
    "\n",
    "# Assuming butter_bandpass_filter and apply_hamming_filter are already defined\n",
    "process_lfp_data(resampled_data, fs_resampled, real_peaks, select_chan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "746ed61b-18ee-4183-9ebd-a5056699e993",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "121984cd0fbf496abee2a7ad7c76c7ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='success', description='Save Plots', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waveforms min/max: -0.06174572981701603 0.06025774374594331\n",
      "Heatmap min/max: -0.4981603936533857 0.5139616195482103\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "825a5744eee54ad5820fef0f7102629e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntRangeSlider(value=(1, 23), continuous_update=False, description='Channels', max=23, min=1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9e16cb496cc4e59b265d92c5743483f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatRangeSlider(value=(-0.5139616195482103, 0.5139616195482103), continuous_update=False, description='Amplit…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to 'csd_analysis.csv' and 'csd_max_min.csv'.\n"
     ]
    }
   ],
   "source": [
    "def save_figure(fig, filename):\n",
    "    fig.savefig(filename, format='svg')\n",
    "\n",
    "def apply_laplacian_filter(data):\n",
    "    filtered_data = np.zeros_like(data)\n",
    "    for chan_idx in range(1, data.shape[0] - 1):  # Skip boundary channels\n",
    "        filtered_data[chan_idx, :] = data[chan_idx + 1, :] - 2 * data[chan_idx, :] + data[chan_idx - 1, :]\n",
    "    filtered_data[0, :] = data[1, :] - data[0, :]  # Forward difference\n",
    "    filtered_data[-1, :] = data[-1, :] - data[-2, :]  # Backward difference\n",
    "    return filtered_data\n",
    "\n",
    "def normalize_heatmap_data(snippets, fs_resampled):\n",
    "    baseline_period = int(0.2 * fs_resampled)  # First 200ms\n",
    "    baseline = np.mean(snippets[:, :, :baseline_period], axis=2, keepdims=True)  # Calculate baseline from the first 200ms\n",
    "    normalized_data = snippets - baseline  # Subtract baseline to normalize\n",
    "    return normalized_data\n",
    "\n",
    "def plot_heatmap_interactive(corrected_snippets, fs_resampled, save_button, heatmap_endpoint):\n",
    "    # Normalize the data by subtracting the first 200ms as baseline\n",
    "    normalized_data = normalize_heatmap_data(corrected_snippets, fs_resampled)\n",
    "    # Convert to microvolts\n",
    "    heatmap_data = np.mean(normalized_data, axis=0) * INT16_TO_UV\n",
    "    print(\"Heatmap min/max:\", heatmap_data.min(), heatmap_data.max())\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "    channel_slider = widgets.IntRangeSlider(\n",
    "        value=[1, heatmap_data.shape[0]],  # start from 1\n",
    "        min=1,  # starting from 1\n",
    "        max=heatmap_data.shape[0],\n",
    "        step=1,\n",
    "        description=\"Channels\",\n",
    "        continuous_update=False,\n",
    "    )\n",
    "\n",
    "    max_abs_val = max(abs(heatmap_data.min()), abs(heatmap_data.max()))\n",
    "    amplitude_range = [-max_abs_val, max_abs_val]\n",
    "    amplitude_slider = widgets.FloatRangeSlider(\n",
    "        value=amplitude_range,\n",
    "        min=-max_abs_val,\n",
    "        max=max_abs_val,\n",
    "        step=(2 * max_abs_val) / 100,\n",
    "        description=\"Amplitude (μV)\",\n",
    "        continuous_update=False,\n",
    "    )\n",
    "\n",
    "    def update_plot(channel_range, amplitude_range):\n",
    "        selected_channels = heatmap_data[channel_range[0]-1:channel_range[1], :]\n",
    "        vmin, vmax = amplitude_range\n",
    "\n",
    "        ax.clear()\n",
    "        im = ax.imshow(\n",
    "            selected_channels,\n",
    "            aspect=\"auto\",\n",
    "            cmap=\"jet\",\n",
    "            extent=[-300, 300, channel_range[1], channel_range[0]],\n",
    "            vmin=vmin,\n",
    "            vmax=vmax,\n",
    "        )\n",
    "        ax.set_xlabel(\"Time (ms)\")\n",
    "        ax.set_ylabel(\"Channel\")\n",
    "        ax.set_title(\"CSD Heatmap\")\n",
    "\n",
    "        if not hasattr(update_plot, \"colorbar\") or update_plot.colorbar is None:\n",
    "            update_plot.colorbar = fig.colorbar(im, ax=ax, label=\"Amplitude (μV)\")\n",
    "        else:\n",
    "            im.set_clim(vmin, vmax)\n",
    "            update_plot.colorbar.set_label(\"Amplitude (μV)\")\n",
    "        plt.draw()\n",
    "\n",
    "    widgets.interactive(\n",
    "        update_plot,\n",
    "        channel_range=channel_slider,\n",
    "        amplitude_range=amplitude_slider,\n",
    "    )\n",
    "\n",
    "    display(channel_slider, amplitude_slider)\n",
    "    update_plot(channel_slider.value, amplitude_slider.value)\n",
    "\n",
    "    def on_save_button_clicked(b):\n",
    "        save_path = os.path.join(cleaned_path[:-4] + \"_csd_heatmap.svg\")\n",
    "        save_figure(fig, save_path)\n",
    "        print(f\"Heatmap saved to {save_path}\")\n",
    "\n",
    "    save_button.on_click(on_save_button_clicked)\n",
    "\n",
    "def plot_averaged_waveforms(averaged_waveforms, channels_to_plot, fs_resampled, save_button):\n",
    "    time = np.linspace(-0.3, 0.3, averaged_waveforms.shape[1])\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    # Convert to microvolts for plotting\n",
    "    for i, waveform in enumerate(averaged_waveforms):\n",
    "        ax.plot(time, waveform, label=f'Channel {channels_to_plot[i]+1}')\n",
    "    ax.set_xlabel('Time (s)')\n",
    "    ax.set_ylabel('Amplitude (μV)')\n",
    "    ax.set_title('Averaged CSD Sweep Waveforms')\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "    print(\"Waveforms min/max:\", averaged_waveforms.min(), averaged_waveforms.max())\n",
    "\n",
    "    def on_save_button_clicked(b):\n",
    "        save_path = os.path.join(cleaned_path[:-4] + \"_csd_averaged_waveforms.svg\")\n",
    "        save_figure(fig, save_path)\n",
    "        print(f\"Averaged waveforms saved to {save_path}\")\n",
    "\n",
    "    save_button.on_click(on_save_button_clicked)\n",
    "\n",
    "def process_csd_data(resampled_data, fs_resampled, real_peaks, select_chan):\n",
    "    channels_to_plot_str = select_chan.strip()\n",
    "    channels_to_plot = []\n",
    "    if channels_to_plot_str:\n",
    "        for part in channels_to_plot_str.split(\",\"):\n",
    "            part = part.strip()\n",
    "            if \"-\" in part:\n",
    "                start, end = map(int, part.split(\"-\"))\n",
    "                channels_to_plot.extend(range(start-1, end))  # Convert to 0-based index\n",
    "            else:\n",
    "                channels_to_plot.append(int(part) - 1)  # Convert to 0-based index\n",
    "\n",
    "    bandpass_data = butter_bandpass_filter(resampled_data, 1, 30, fs_resampled)\n",
    "    hamming_filtered_data = apply_hamming_filter(bandpass_data, fs_resampled)\n",
    "    filtered_data = hamming_filtered_data\n",
    "\n",
    "    csd_data = apply_laplacian_filter(filtered_data)\n",
    "    snippet_range = int(0.3 * fs_resampled)\n",
    "    snippets = []\n",
    "    for peak in real_peaks:\n",
    "        if peak - snippet_range >= 0 and peak + snippet_range < csd_data.shape[1]:\n",
    "            snippets.append(csd_data[:, peak - snippet_range:peak + snippet_range])\n",
    "    snippets = np.array(snippets)\n",
    "\n",
    "    baseline_period = int(0.2 * fs_resampled)\n",
    "    baselines = snippets[:, :, :baseline_period].mean(axis=2, keepdims=True)\n",
    "    corrected_snippets = snippets - baselines\n",
    "\n",
    "    # Convert corrected_snippets to μV for all subsequent analyses/plots/exports\n",
    "    corrected_snippets_uv = corrected_snippets * INT16_TO_UV\n",
    "\n",
    "    averaged_waveforms = np.mean(corrected_snippets_uv[:, channels_to_plot, :], axis=0)\n",
    "\n",
    "    save_button = widgets.Button(description=\"Save Plots\", button_style='success')\n",
    "    display(save_button)\n",
    "\n",
    "    plot_averaged_waveforms(averaged_waveforms, channels_to_plot, fs_resampled, save_button)\n",
    "\n",
    "    total_noisy_duration = sum(end - start for start, end in noisy_intervals)\n",
    "    total_file_duration = resampled_data.shape[1] / fs_resampled\n",
    "    effective_duration = total_file_duration - total_noisy_duration\n",
    "    recurrence_frequency = len(real_peaks) / effective_duration if effective_duration > 0 else 0\n",
    "\n",
    "    max_peaks = np.max(corrected_snippets_uv[:, channels_to_plot, :], axis=2)\n",
    "    min_peaks = np.min(corrected_snippets_uv[:, channels_to_plot, :], axis=2)\n",
    "\n",
    "    heatmap_endpoint = max(np.abs(max_peaks).max(), np.abs(min_peaks).max())\n",
    "\n",
    "    avg_max_peaks = np.mean(max_peaks, axis=0)\n",
    "    avg_min_peaks = np.mean(min_peaks, axis=0)\n",
    "    averaged_waveform_peaks = np.max(np.abs(averaged_waveforms), axis=1)\n",
    "    max_channel_idx = channels_to_plot[np.argmax(averaged_waveform_peaks)] + 1\n",
    "\n",
    "    isi_list = []\n",
    "    real_peaks = np.array(real_peaks)\n",
    "    for i in range(1, len(real_peaks)):\n",
    "        prev_peak_time = real_peaks[i-1] / fs_resampled\n",
    "        curr_peak_time = real_peaks[i] / fs_resampled\n",
    "        isi_noisy = False\n",
    "        for start, end in noisy_intervals:\n",
    "            if (prev_peak_time < end and curr_peak_time > start):\n",
    "                isi_noisy = True\n",
    "                break\n",
    "        if isi_noisy:\n",
    "            isi_list.append(np.nan)\n",
    "        else:\n",
    "            isi_list.append(curr_peak_time - prev_peak_time)\n",
    "    isi_list = np.array(isi_list)\n",
    "    isi_mean = np.nanmean(isi_list) if np.any(~np.isnan(isi_list)) else np.nan\n",
    "\n",
    "    plot_heatmap_interactive(corrected_snippets, fs_resampled, save_button, heatmap_endpoint)\n",
    "\n",
    "    max_min_peaks_data = {\n",
    "        f\"Channel {channels_to_plot[i] + 1} Max Peaks (μV)\": max_peaks[:, i]\n",
    "        for i in range(len(channels_to_plot))\n",
    "    }\n",
    "    max_min_peaks_data.update({\n",
    "        f\"Channel {channels_to_plot[i] + 1} Min Peaks (μV)\": min_peaks[:, i]\n",
    "        for i in range(len(channels_to_plot))\n",
    "    })\n",
    "    max_min_peaks_df = pd.DataFrame(max_min_peaks_data)\n",
    "\n",
    "    isi_df = pd.DataFrame({\"ISI List (s)\": isi_list})\n",
    "    max_min_peaks_df = pd.concat([max_min_peaks_df, isi_df], axis=1)\n",
    "    max_min_peaks_df.to_csv(os.path.join(cleaned_path[:-4]+\"_csd_max_min.csv\"), index=False)\n",
    "\n",
    "    results = {\n",
    "        \"Recurrence Frequency (Hz)\": [recurrence_frequency],\n",
    "        \"ISI Mean (s)\": [isi_mean],\n",
    "    }\n",
    "    for i, chan in enumerate(channels_to_plot):\n",
    "        results[f\"Avg Max Peak (Channel {chan + 1}) (μV)\"] = [avg_max_peaks[i]]\n",
    "        results[f\"Avg Min Peak (Channel {chan + 1}) (μV)\"] = [avg_min_peaks[i]]\n",
    "    results[\"Channel with Highest Average Peak\"] = [max_channel_idx]\n",
    "    results_df = pd.DataFrame.from_dict(results, orient=\"index\").T\n",
    "    results_df.to_csv(os.path.join(cleaned_path[:-4]+\"_csd_analysis.csv\"), index=False)\n",
    "    print(\"Results saved to 'csd_analysis.csv' and 'csd_max_min.csv'.\")\n",
    "\n",
    "# Assuming butter_bandpass_filter and apply_hamming_filter are already defined\n",
    "process_csd_data(resampled_data, fs_resampled, real_peaks, select_chan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c93b069b-22a7-4a82-b844-a799d8ba0e76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac783965e3374558b5ee00df45d7db79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='success', description='Save Plots', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3957fcd61c24a768fe0ede9a9da1cc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntRangeSlider(value=(1, 23), continuous_update=False, description='Channels', max=23, min=1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fee142016a447e781758b22818811cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatRangeSlider(value=(-0.0004299720597861914, 0.0004299720597861914), continuous_update=False, description='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to 'mua_analysis.csv' and 'mua_max_min_peaks.csv'.\n"
     ]
    }
   ],
   "source": [
    "def save_figure(fig, filename):\n",
    "    fig.savefig(filename, format='svg')\n",
    "\n",
    "defacto_peaks = [peak * 10 for peak in real_peaks]\n",
    "\n",
    "def butter_highpass_filter(data, cutoff, fs, order=4):\n",
    "    nyquist = 0.5 * fs\n",
    "    normal_cutoff = cutoff / nyquist\n",
    "    b, a = butter(order, normal_cutoff, btype='high', analog=False)\n",
    "    filtered_data = filtfilt(b, a, data, axis=1)\n",
    "    return filtered_data\n",
    "\n",
    "def normalize_heatmap_data(snippets, fs):\n",
    "    baseline_period = int((snippets.shape[-1]) / 3)\n",
    "    baseline = np.mean(snippets[:, :, :baseline_period], axis=2, keepdims=True)\n",
    "    normalized_data = snippets - baseline\n",
    "    return normalized_data\n",
    "\n",
    "def smooth_data_with_kernel(data, kernel_size, stride):\n",
    "    kernel = np.ones(kernel_size) / kernel_size\n",
    "    smoothed_data = np.apply_along_axis(lambda m: np.convolve(m, kernel, mode='valid')[::stride], axis=-1, arr=data)\n",
    "    return smoothed_data\n",
    "\n",
    "def plot_heatmap_interactive(corrected_snippets, fs, save_button, heatmap_endpoint):\n",
    "    normalized_data = normalize_heatmap_data(corrected_snippets, fs)\n",
    "    # Convert to microvolt\n",
    "    heatmap_data = np.mean(normalized_data, axis=0) * INT16_TO_UV\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "    channel_slider = widgets.IntRangeSlider(\n",
    "        value=[1, heatmap_data.shape[0]],\n",
    "        min=1,\n",
    "        max=heatmap_data.shape[0],\n",
    "        step=1,\n",
    "        description=\"Channels\",\n",
    "        continuous_update=False,\n",
    "    )\n",
    "\n",
    "    max_abs_val = max(abs(heatmap_data.min()), abs(heatmap_data.max()))\n",
    "    amplitude_range = [-max_abs_val, max_abs_val]\n",
    "    amplitude_slider = widgets.FloatRangeSlider(\n",
    "        value=amplitude_range,\n",
    "        min=-max_abs_val,\n",
    "        max=max_abs_val,\n",
    "        step=(2 * max_abs_val) / 100,\n",
    "        description=\"Amplitude (μV)\",\n",
    "        continuous_update=False,\n",
    "    )\n",
    "\n",
    "    def update_plot(channel_range, amplitude_range):\n",
    "        selected_channels = heatmap_data[channel_range[0]-1:channel_range[1], :]\n",
    "        vmin, vmax = amplitude_range\n",
    "\n",
    "        ax.clear()\n",
    "        im = ax.imshow(\n",
    "            selected_channels,\n",
    "            aspect=\"auto\",\n",
    "            cmap=\"jet_r\",\n",
    "            extent=[-300, 300, channel_range[1], channel_range[0]],\n",
    "            vmin=-vmax,\n",
    "            vmax=vmax,\n",
    "        )\n",
    "        ax.set_xlabel(\"Time (ms)\")\n",
    "        ax.set_ylabel(\"Channel\")\n",
    "        ax.set_title(\"MUA Heatmap\")\n",
    "\n",
    "        if not hasattr(update_plot, \"colorbar\") or update_plot.colorbar is None:\n",
    "            update_plot.colorbar = fig.colorbar(im, ax=ax, label=\"Amplitude (μV)\")\n",
    "        else:\n",
    "            im.set_clim(-vmax, vmax)\n",
    "            update_plot.colorbar.set_ticks([-vmax, 0, vmax])\n",
    "            update_plot.colorbar.set_label(\"Amplitude (μV)\")\n",
    "\n",
    "        plt.draw()\n",
    "\n",
    "    widgets.interactive(\n",
    "        update_plot,\n",
    "        channel_range=channel_slider,\n",
    "        amplitude_range=amplitude_slider,\n",
    "    )\n",
    "\n",
    "    display(channel_slider, amplitude_slider)\n",
    "    update_plot(channel_slider.value, amplitude_slider.value)\n",
    "\n",
    "    def on_save_button_clicked(b):\n",
    "        save_path = os.path.join(cleaned_path[:-4] + \"_mua_heatmap.svg\")\n",
    "        save_figure(fig, save_path)\n",
    "        print(f\"Heatmap saved to {save_path}\")\n",
    "\n",
    "    save_button.on_click(on_save_button_clicked)\n",
    "\n",
    "def plot_averaged_waveforms(averaged_waveforms, channels_to_plot, fs, save_button):\n",
    "    time = np.linspace(-0.3, 0.3, averaged_waveforms.shape[1])\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    # Convert to microvolt for plotting\n",
    "    for i, waveform in enumerate(averaged_waveforms):\n",
    "        ax.plot(time, waveform, label=f'Channel {channels_to_plot[i]+1}')\n",
    "    ax.set_xlabel('Time (s)')\n",
    "    ax.set_ylabel('Amplitude (μV)')\n",
    "    ax.set_title('Averaged MUA Sweep Waveforms')\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "\n",
    "    def on_save_button_clicked(b):\n",
    "        save_path = os.path.join(cleaned_path[:-4] + \"_mua_averaged_waveforms.svg\")\n",
    "        save_figure(fig, save_path)\n",
    "        print(f\"Averaged waveforms saved to {save_path}\")\n",
    "\n",
    "    save_button.on_click(on_save_button_clicked)\n",
    "\n",
    "def plot_highest_event_all_channels(snippets, fs, channels_to_plot, target_chan_idx, save_button):\n",
    "    # Find event with highest peak on target channel\n",
    "    snippet_peaks = np.max(np.abs(snippets[:, target_chan_idx, :]), axis=1)\n",
    "    max_idx = np.argmax(snippet_peaks)\n",
    "    plot_snippet = snippets[max_idx, channels_to_plot, :] * INT16_TO_UV\n",
    "\n",
    "    time = np.linspace(-0.3, 0.3, plot_snippet.shape[1])\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    for i, chan_idx in enumerate(channels_to_plot):\n",
    "        ax.plot(time, plot_snippet[i], label=f'Channel {chan_idx+1}')\n",
    "    ax.set_xlabel('Time (s)')\n",
    "    ax.set_ylabel('Amplitude (μV)')\n",
    "    ax.set_title(f'Waveforms of Highest Event on Target Channel {target_chan_idx+1} (Event {max_idx+1})')\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "\n",
    "    def on_save_button_clicked(b):\n",
    "        save_path = os.path.join(cleaned_path[:-4] + f\"_mua_highest_event_all_channels.svg\")\n",
    "        save_figure(fig, save_path)\n",
    "        print(f\"Highest event waveforms saved to {save_path}\")\n",
    "\n",
    "    save_button.on_click(on_save_button_clicked)\n",
    "\n",
    "def process_mua_data(resampled_data, fs, real_peaks, select_chan):\n",
    "    channels_to_plot_str = select_chan.strip()\n",
    "    channels_to_plot = []\n",
    "    if channels_to_plot_str:\n",
    "        for part in channels_to_plot_str.split(\",\"):\n",
    "            part = part.strip()\n",
    "            if \"-\" in part:\n",
    "                start, end = map(int, part.split(\"-\"))\n",
    "                channels_to_plot.extend(range(start-1, end))\n",
    "            else:\n",
    "                channels_to_plot.append(int(part) - 1)\n",
    "\n",
    "    filtered_data = butter_highpass_filter(resampled_data, 500, fs)\n",
    "\n",
    "    snippet_range = int(0.3 * fs)\n",
    "    snippets = []\n",
    "    for peak in defacto_peaks:\n",
    "        if peak - snippet_range >= 0 and peak + snippet_range < filtered_data.shape[1]:\n",
    "            snippets.append(filtered_data[:, peak - snippet_range:peak + snippet_range])\n",
    "    snippets = np.array(snippets)\n",
    "\n",
    "    normalized_snippets = normalize_heatmap_data(snippets, fs)\n",
    "    smoothed_snippets = smooth_data_with_kernel(normalized_snippets, kernel_size=21, stride=7)\n",
    "    abs_snippets = np.abs(smoothed_snippets)\n",
    "    abs_norm_snippets = normalize_heatmap_data(abs_snippets, fs)\n",
    "\n",
    "    # Convert to microvolt for all further analysis and plotting\n",
    "    abs_norm_snippets_uv = abs_norm_snippets * INT16_TO_UV\n",
    "\n",
    "    averaged_waveforms = np.mean(abs_norm_snippets_uv[:, channels_to_plot, :], axis=0)\n",
    "\n",
    "    save_button = widgets.Button(description=\"Save Plots\", button_style='success')\n",
    "    display(save_button)\n",
    "\n",
    "    target_chan_idx = int(target_chan_text.value.strip()) - 1\n",
    "    plot_averaged_waveforms(averaged_waveforms, channels_to_plot, fs, save_button)\n",
    "    plot_highest_event_all_channels(abs_norm_snippets, fs, channels_to_plot, target_chan_idx, save_button)\n",
    "\n",
    "    total_noisy_duration = sum(end - start for start, end in noisy_intervals)\n",
    "    total_file_duration = loaded_data.shape[1] / fs\n",
    "    effective_duration = total_file_duration - total_noisy_duration\n",
    "    recurrence_frequency = len(defacto_peaks) / effective_duration if effective_duration > 0 else 0\n",
    "\n",
    "    max_peaks = np.max(abs_norm_snippets[:, channels_to_plot, :], axis=2)\n",
    "    min_peaks = np.min(abs_norm_snippets[:, channels_to_plot, :], axis=2)\n",
    "\n",
    "    heatmap_endpoint = max(np.abs(max_peaks).max(), np.abs(min_peaks).max())\n",
    "    avg_max_peaks = np.mean(max_peaks, axis=0)\n",
    "    avg_min_peaks = np.mean(min_peaks, axis=0)\n",
    "    averaged_waveform_peaks = np.max(np.abs(averaged_waveforms), axis=1)\n",
    "    max_channel_idx = channels_to_plot[np.argmax(averaged_waveform_peaks)] + 1\n",
    "\n",
    "    isi_list = []\n",
    "    real_peaks = np.array(real_peaks)\n",
    "    for i in range(1, len(real_peaks)):\n",
    "        prev_peak_time = real_peaks[i-1] / fs\n",
    "        curr_peak_time = real_peaks[i] / fs\n",
    "        isi_noisy = False\n",
    "        for start, end in noisy_intervals:\n",
    "            if (prev_peak_time < end and curr_peak_time > start):\n",
    "                isi_noisy = True\n",
    "                break\n",
    "        if isi_noisy:\n",
    "            isi_list.append(np.nan)\n",
    "        else:\n",
    "            isi_list.append(curr_peak_time - prev_peak_time)\n",
    "    isi_list = np.array(isi_list)\n",
    "    isi_mean = np.nanmean(isi_list) if np.any(~np.isnan(isi_list)) else np.nan\n",
    "\n",
    "    # For the heatmap, pass the unconverted abs_snippets (since the conversion is inside the function)\n",
    "    plot_heatmap_interactive(abs_snippets, fs, save_button, heatmap_endpoint)\n",
    "\n",
    "    max_min_peaks_data = {\n",
    "        f\"Channel {channels_to_plot[i] + 1} Max Peaks (μV)\": max_peaks[:, i]\n",
    "        for i in range(len(channels_to_plot))\n",
    "    }\n",
    "    max_min_peaks_data.update({\n",
    "        f\"Channel {channels_to_plot[i] + 1} Min Peaks (μV)\": min_peaks[:, i]\n",
    "        for i in range(len(channels_to_plot))\n",
    "    })\n",
    "    max_min_peaks_df = pd.DataFrame(max_min_peaks_data)\n",
    "\n",
    "    isi_df = pd.DataFrame({\"ISI List (s)\": isi_list})\n",
    "    max_min_peaks_df = pd.concat([max_min_peaks_df, isi_df], axis=1)\n",
    "\n",
    "    max_min_peaks_df.to_csv(os.path.join(cleaned_path[:-4] + \"_mua_max_min_peaks.csv\"), index=False)\n",
    "\n",
    "    results = {\n",
    "        \"Recurrence Frequency (Hz)\": [recurrence_frequency],\n",
    "        \"ISI Mean (s)\": [isi_mean],\n",
    "    }\n",
    "    for i, chan in enumerate(channels_to_plot):\n",
    "        results[f\"Avg Max Peak (Channel {chan + 1}) (μV)\"] = [avg_max_peaks[i]]\n",
    "        results[f\"Avg Min Peak (Channel {chan + 1}) (μV)\"] = [avg_min_peaks[i]]\n",
    "    results[\"Channel with Highest Average Peak\"] = [max_channel_idx]\n",
    "    results_df = pd.DataFrame.from_dict(results, orient=\"index\").T\n",
    "    results_df.to_csv(os.path.join(cleaned_path[:-4] + \"_mua_analysis.csv\"), index=False)\n",
    "\n",
    "    print(\"Results saved to 'mua_analysis.csv' and 'mua_max_min_peaks.csv'.\")\n",
    "\n",
    "# Assuming butter_bandpass_filter and apply_hamming_filter are already defined\n",
    "process_mua_data(loaded_data, fs, defacto_peaks, select_chan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aacc22e4-3950-4876-bde3-df5e2184e0ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
